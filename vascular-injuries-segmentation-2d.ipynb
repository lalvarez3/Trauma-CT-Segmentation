{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djzZ-bffGr8X"
   },
   "source": [
    "#### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "biFwQV_yGr8X",
    "outputId": "caa6e216-4409-4de4-bc5a-ceec09bf6af7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.1\n",
      "Numpy version: 1.22.3\n",
      "Pytorch version: 1.11.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 71ff399a3ea07aef667b23653620a290364095b1\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.2\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.4.0\n",
      "TorchVision version: 0.12.0\n",
      "tqdm version: 4.64.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.2\n",
      "einops version: 0.4.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ipywidgets.widgets import *\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureType,\n",
    "    EnsureChannelFirstd,\n",
    "    RandFlipd,\n",
    "    RandRotated,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    KeepLargestConnectedComponent,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityd,\n",
    "    SpatialPadd,\n",
    ")\n",
    "\n",
    "import wandb\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceFocalLoss, GeneralizedDiceLoss\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import (\n",
    "    CacheDataset,\n",
    "    list_data_collate,\n",
    "    decollate_batch,\n",
    "    Dataset,\n",
    "    LMDBDataset,\n",
    "    create_test_image_2d,\n",
    ")\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from monai.data import DataLoader\n",
    "import os\n",
    "import glob\n",
    "from monai.transforms.spatial.array import Resize\n",
    "\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "from typing import Any, Dict, Hashable, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "\n",
    "from monai.config import DtypeLike, KeysCollection\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "from monai.networks.layers import AffineTransform\n",
    "from monai.networks.layers.simplelayers import GaussianFilter\n",
    "from monai.transforms.croppad.array import CenterSpatialCrop, SpatialPad\n",
    "from monai.transforms.inverse import InvertibleTransform\n",
    "from monai.transforms.spatial.array import (\n",
    "    Resize,\n",
    ")\n",
    "from monai.transforms.transform import MapTransform, RandomizableTransform\n",
    "from monai.transforms.utils import create_grid\n",
    "from monai.utils import (\n",
    "    InterpolateMode,\n",
    "    ensure_tuple_rep,\n",
    ")\n",
    "from monai.utils.deprecate_utils import deprecated_arg\n",
    "from monai.utils.enums import TraceKeys\n",
    "from monai.utils.module import optional_import\n",
    "from monai.utils.type_conversion import convert_data_type, convert_to_dst_type\n",
    "from monai.apps import load_from_mmar\n",
    "from monai.apps.mmars import RemoteMMARKeys\n",
    "from monai.networks.utils import copy_model_state\n",
    "from monai.optimizers import generate_param_groups\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "from monai.visualize import matshow3d, blend_images\n",
    "import imageio\n",
    "\n",
    "print_config()\n",
    "from monai.losses import GeneralizedWassersteinDiceLoss\n",
    "import random\n",
    "import tempfile\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeepOnlyClass(MapTransform, InvertibleTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        class_to_keep: int,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.class_to_keep = class_to_keep\n",
    "\n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            self.push_transform(d, key)\n",
    "            d[key] = np.where(d[key] == 255, 1, 0)\n",
    "            # values = d[key]\n",
    "            # print(\"NP UNIQUE\", np.unique(values))\n",
    "            # print('BEFORE EYE', d[key].shape)\n",
    "            # n_values = np.max(values) + 1\n",
    "            # d[key]= np.eye(n_values)[values]\n",
    "            # print('AFTER EYE', d[key].shape)\n",
    "            # d[key] = np.squeeze(d[key])\n",
    "            # print('AFTER squeeze', d[key].shape)\n",
    "            # print(\"NP UNIQUE AFTER\", np.unique(d[key]))\n",
    "            # if d[key].ndim == 2:\n",
    "            #     zeros = np.zeros(d[key].shape)\n",
    "            #     d[key] = np.stack([d[key], zeros], axis=-1)\n",
    "            #     print(d[key].shape)\n",
    "            # print(\"NP UNIQUE AFTER AFTER 0\", np.unique(d[key][:,:,0]))\n",
    "            # print(\"NP UNIQUE AFTER AFTER 1\", np.unique(d[key][:,:,1]))\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveAlpha(MapTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            if key == \"label\":\n",
    "                d[key] = d[key][...,:1]\n",
    "            else:\n",
    "                d[key] = d[key][...,:3]\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToGrayScale(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        normalize: bool = False,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            d[key] = d[key][..., :1]\n",
    "            if self.normalize:\n",
    "                d[key] = d[key] / 255\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED = False\n",
    "TRANSFER_LEARNING = False\n",
    "N_WORKERS_LOADER = 0\n",
    "N_WORKERS_CACHE = 0\n",
    "CACHE_RATE = 0\n",
    "SEED = 42\n",
    "BS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WzCJRUGGr8a"
   },
   "source": [
    "#### Define the LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spleen_data\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = \"spleen_data\"\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(pytorch_lightning.LightningModule):\n",
    "    def __init__(self, train_img_size, val_img_size, n_output):\n",
    "        super().__init__()\n",
    "        self.train_img_size = train_img_size\n",
    "        self.val_img_size = val_img_size\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self._model = UNet(\n",
    "            spatial_dims=2,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.loss_function = DiceCELoss(to_onehot_y=True, softmax=True, jaccard=True)\n",
    "        self.post_pred = Compose([EnsureType(), Activations(softmax=True), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "        self.train_dice_metric = DiceMetric(\n",
    "            include_background=True, reduction=\"mean_batch\",  get_not_nans=False\n",
    "        )\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.save_hyperparameters()  # save hyperparameters\n",
    "\n",
    "        # self.logger.expe.init(self.hparams)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        tempdir = \"synthetic_data\"\n",
    "\n",
    "        print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "        if not glob.glob(os.path.join(tempdir, \"img*.png\")):\n",
    "            for i in range(40):\n",
    "                im, seg = create_test_image_2d(512, 512, num_seg_classes=1)\n",
    "                Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
    "                Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n",
    "        \n",
    "        lnp.lnp(f\"Tempdir: {tempdir}\")\n",
    "\n",
    "        images = sorted(glob.glob(os.path.join(tempdir, \"img*.png\")))\n",
    "        segs = sorted(glob.glob(os.path.join(tempdir, \"seg*.png\")))\n",
    "        \n",
    "        # train_images = sorted(\n",
    "        #     glob.glob(\n",
    "        #         os.path.join(\n",
    "        #             \"u://\",\n",
    "        #             \"lauraalvarez\",\n",
    "        #             \"data\",\n",
    "        #             \"vascular_injuries\",\n",
    "        #             \"png\",\n",
    "        #             \"imagesTr\",\n",
    "        #             \"*.png\",\n",
    "        #         )\n",
    "        #     )\n",
    "        # )\n",
    "        \n",
    "\n",
    "        # train_labels = [img.replace(\"imagesTr\", \"labelsTr\") for img in train_images]\n",
    "\n",
    "        # data_dicts = [\n",
    "        #     {\"image\": image_name, \"label\": label_name}\n",
    "        #     for image_name, label_name in zip(train_images, train_labels)\n",
    "        # ]\n",
    "\n",
    "        # Codigo para train sintetico\n",
    "        data_dicts = [\n",
    "            {\"image\": image_name, \"label\": label_name}\n",
    "            for image_name, label_name in zip(images, segs)\n",
    "            ]\n",
    "        \n",
    "\n",
    "        # test_images = sorted(\n",
    "        #     glob.glob(\n",
    "        #         os.path.join(\n",
    "        #             \"U:\\\\\",\n",
    "        #             \"lauraalvarez\",\n",
    "        #             \"data\",\n",
    "        #             \"vascular_injuries\",\n",
    "        #             \"png\",\n",
    "        #             \"imagesTs\",\n",
    "        #             \"*.png\",\n",
    "        #         )\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "\n",
    "        # test_labels = [img.replace(\"imagesTs\", \"labelsTs\") for img in test_images]\n",
    "\n",
    "        # data_dicts_test = [\n",
    "        #     {\"image\": image_name, \"label\": label_name}\n",
    "        #     for image_name, label_name in zip(test_images, test_labels)\n",
    "        # ]\n",
    "\n",
    "\n",
    "        # Codigo para test sintetico\n",
    "        if not glob.glob(os.path.join(tempdir, \"img_test*.png\")):\n",
    "            for i in range(5):\n",
    "                im_test, seg_test = create_test_image_2d(512, 512, num_seg_classes=1)\n",
    "                Image.fromarray((im_test * 255).astype(\"uint8\")).save(os.path.join(str(tempdir), f\"img_test{i:d}.png\"))\n",
    "                Image.fromarray((seg_test * 255).astype(\"uint8\")).save(os.path.join(str(tempdir), f\"seg_test{i:d}.png\"))\n",
    "        \n",
    "        images_test = sorted(glob.glob(os.path.join(tempdir, \"img_test*.png\")))\n",
    "        segs_test = sorted(glob.glob(os.path.join(tempdir, \"seg_test*.png\")))\n",
    "        \n",
    "        data_dicts_test = [\n",
    "            {\"image\": image_name, \"label\": label_name}\n",
    "            for image_name, label_name in zip(images_test, segs_test)\n",
    "        ]\n",
    "\n",
    "        random.shuffle(data_dicts)\n",
    "        train_files, val_files = data_dicts, data_dicts_test\n",
    "        print(\"len(train_files)\", len(train_files))\n",
    "        print(\"len(validation files)\", len(val_files))\n",
    "\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=SEED)\n",
    "\n",
    "        train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                RemoveAlpha(keys=[\"image\", \"label\"]),\n",
    "                ScaleIntensityd(keys=[\"image\"]),\n",
    "                KeepOnlyClass(keys=[\"label\"], class_to_keep=255),\n",
    "                ToGrayScale(keys=[\"image\"], normalize=False),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                Resized(keys=[\"image\", \"label\"], spatial_size=(256, 256)),\n",
    "                RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=(96, 96), max_roi_size = (96, 96),random_size=False),\n",
    "                SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(96, 96)),\n",
    "                RandFlipd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    spatial_axis=[0],\n",
    "                    prob=0.10,\n",
    "                ),\n",
    "                RandFlipd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    spatial_axis=[0],\n",
    "                    prob=0.10,\n",
    "                ),\n",
    "                RandFlipd(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    spatial_axis=[1],\n",
    "                    prob=0.10,\n",
    "                ),\n",
    "                RandRotate90d(\n",
    "                    keys=[\"image\", \"label\"],\n",
    "                    prob=0.10,\n",
    "                    max_k=3,\n",
    "                ),\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # define the data transforms\n",
    "        val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                RemoveAlpha(keys=[\"image\", \"label\"]),\n",
    "                ScaleIntensityd(keys=[\"image\"]),\n",
    "                KeepOnlyClass(keys=[\"label\"], class_to_keep=255),\n",
    "                ToGrayScale(keys=[\"image\"], normalize=False),\n",
    "                EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_ds = Dataset(\n",
    "            data=train_files,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "\n",
    "        self.val_ds = Dataset(\n",
    "            data=val_files,\n",
    "            transform=val_transforms,\n",
    "        )\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "                self._model.parameters(), lr=0.1, momentum=0.99, nesterov=True, weight_decay=3e-05\n",
    "            )\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda epoch: (1 - self.current_epoch / 1000) ** 0.9,\n",
    "            last_epoch= self.current_epoch -1,\n",
    "            verbose=True,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=BS,\n",
    "            shuffle=True,\n",
    "            num_workers=N_WORKERS_LOADER,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            self.val_ds,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=N_WORKERS_LOADER,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        return val_loader\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        predict_dataloader = torch.utils.data.DataLoader(\n",
    "            self.val_ds, batch_size=1, shuffle=False, num_workers=N_WORKERS_LOADER\n",
    "        )\n",
    "        return predict_dataloader\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        # lnp.lnp(images.shape)\n",
    "        output = self.forward(images)\n",
    "        # roi_size = (96, 96)\n",
    "        # sw_batch_size = 4\n",
    "        # output = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(output)]\n",
    "\n",
    "        loss = self.loss_function(output, labels)\n",
    "\n",
    "        labels_1 = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(output)]\n",
    "        self.train_dice_metric(y_pred=outputs, y=labels_1)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        #  the function is called after every epoch is completed\n",
    "\n",
    "        dice_injure = self.train_dice_metric.aggregate()\n",
    "        dice_injure = dice_injure[0]\n",
    "        self.train_dice_metric.reset()\n",
    "        # calculating average loss\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "\n",
    "        # logging using tensorboard logger\n",
    "        self.log(\"dice loss\", avg_loss, logger=False)\n",
    "        # self.log(\"train liver dice\", dice_liver)\n",
    "        self.log(\"train injure dice\", dice_injure, logger=False)\n",
    "\n",
    "        self.logger.experiment.log({\"dice loss\": avg_loss})\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        # filenames = batch[\"path\"]\n",
    "        # post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        # post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "        roi_size = (96, 96)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(\n",
    "            images, roi_size, sw_batch_size, self.forward\n",
    "        )\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        predicition = {\n",
    "            \"output\": outputs,\n",
    "            \"image\": images,\n",
    "            \"label\": labels,\n",
    "        }\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [\n",
    "            self.post_label(i) for i in decollate_batch(labels)\n",
    "        ]\n",
    "\n",
    "        # labels = [post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        return {\n",
    "            \"dice_metric\": self.dice_metric,\n",
    "            \"val_number\": len(outputs),\n",
    "            \"prediction\": predicition,\n",
    "            \"val_loss\": loss,\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "\n",
    "        # val_loss, num_items = 0, 0\n",
    "        # for output in outputs:\n",
    "        #     val_loss += output[\"val_loss\"].sum().item()\n",
    "        #     num_items += output[\"val_number\"]\n",
    "        # mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        mean_val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "\n",
    "        post_pred_dice = Compose(\n",
    "            [\n",
    "                EnsureType(),\n",
    "                AsDiscrete(argmax=True, to_onehot=2),\n",
    "                KeepLargestConnectedComponent([1], is_onehot=True, independent=False),\n",
    "            ]\n",
    "        )\n",
    "        post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "        dice_injure = self.dice_metric.aggregate()\n",
    "        dice_injure = dice_injure[0]\n",
    "        # lnp.lnp(dice_injure)\n",
    "\n",
    "        self.dice_metric.reset()\n",
    "        tensorboard_logs = {\n",
    "            \"dice_metric\": dice_injure,\n",
    "        }\n",
    "        predictions = [x[\"prediction\"] for x in outputs]\n",
    "\n",
    "        if dice_injure > self.best_val_dice:\n",
    "            self.best_val_dice = dice_injure.item()\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            # f\"current liver dice: {dice_liver:.4f}\"\n",
    "            f\"current injure  dice: {dice_injure:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        # self.log(\"dice_metric_liver\", dice_liver.item(), prog_bar=True)\n",
    "        self.log(\"dice_metric_injure\", dice_injure.item(), prog_bar=True, logger=False)\n",
    "        self.log(\"val_loss\", mean_val_loss, prog_bar=True, logger=False)\n",
    "        return {\"log\": tensorboard_logs}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        print(\"predicting...\")\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 2\n",
    "        outputs = sliding_window_inference(\n",
    "            images, roi_size, sw_batch_size, self.forward\n",
    "        )\n",
    "        predicition = {\"output\": outputs, \"image\": images, \"label\": labels}\n",
    "        outputs = [post_pred(i) for i in decollate_batch(outputs)]\n",
    "\n",
    "        labels = [\n",
    "            post_label(torch.unsqueeze(i, 0)).squeeze() for i in decollate_batch(labels)\n",
    "        ]\n",
    "        dice_metric = self.dice_metric(y_pred=outputs, y=labels)\n",
    "        return {\"prediction\": predicition, \"dice_metric\": dice_metric}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gif Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(prediction, filename):\n",
    "    def _save_gif(volume, filename):\n",
    "        volume = volume.astype(np.float64) / np.max(volume) # normalize the data to 0 - 1\n",
    "        volume = 255 * volume # Now scale by 255\n",
    "        volume = volume.astype(np.uint8)\n",
    "        path_to_gif = os.path.join(\"gifs\", f'{filename}.gif')\n",
    "        if not os.path.exists(\"gifs\"):\n",
    "            print(\"Creating gifs directory\")\n",
    "            os.mkdir(\"gifs\")\n",
    "        imageio.mimsave(path_to_gif, volume)\n",
    "        return path_to_gif\n",
    "    post_pred_blending = Compose([EnsureType(), AsDiscrete(argmax=False),KeepLargestConnectedComponent([1,2], is_onehot=False, independent=False)])\n",
    "    prediction[\"output\"] = [post_pred_blending(i) for i in decollate_batch(prediction[\"output\"])]\n",
    "    selected = {\"output\": prediction[\"output\"][0], \"image\": prediction[\"image\"][0], \"label\": prediction[\"label\"][0]}\n",
    "\n",
    "    selected = Resized(keys=[\"image\", \"label\"], spatial_size=(160, 160, 160))(selected)\n",
    "    selected = Resized(keys=[\"output\"], spatial_size=(160, 160, 160))(selected)\n",
    "\n",
    "    selected = {\"output\": selected[\"output\"].unsqueeze(0), \"image\": selected[\"image\"].unsqueeze(0), \"label\": selected[\"label\"].unsqueeze(0)}\n",
    "\n",
    "    # print('true label:', selected['label'].shape)\n",
    "    pred = torch.argmax(selected['output'], dim=1).detach().cpu().numpy()\n",
    "    true_label = selected['label'][0].detach().cpu().numpy()\n",
    "    image = selected['image'][0].cpu().numpy()\n",
    "    # print('true label:', true_label.shape)\n",
    "    \n",
    "    blended_true_label = blend_images(image, true_label, alpha=0.7)\n",
    "    blended_final_true_label = torch.from_numpy(blended_true_label).permute(1,2,0,3)\n",
    "\n",
    "    blended_prediction = blend_images(image, pred, alpha=0.7)\n",
    "    blended_final_prediction = torch.from_numpy(blended_prediction).permute(1,2,0,3)\n",
    "\n",
    "    volume_pred = blended_final_prediction[:,:,:,:]\n",
    "    volume_label = blended_final_true_label[:,:,:,:]\n",
    "    volume_pred = np.squeeze(volume_pred).permute(3,0,1,2).cpu()\n",
    "    volume_label = np.squeeze(volume_label).permute(3,0,1,2).cpu()\n",
    "    volume_img = torch.tensor(image).permute(3,1,2,0).repeat(1,1,1,3).cpu()\n",
    "\n",
    "    volume = torch.hstack((volume_img, volume_pred, volume_label))\n",
    "\n",
    "    volume_path = _save_gif(volume.numpy(), f\"blended-{filename}\")\n",
    "       \n",
    "    \n",
    "    return volume_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_info(prediction):\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "    ground_truth = [\n",
    "            1 if (post_label(i)[2,:,:,:].cpu() == 1).any() else 0 for i in decollate_batch(prediction['label'])\n",
    "        ]\n",
    "\n",
    "    test = prediction['output'].cpu()\n",
    "    prediction_1 = torch.argmax(test, dim=1)\n",
    "\n",
    "    class_2_mask = (prediction_1 == 2).cpu()\n",
    "    if class_2_mask.any():\n",
    "        prediction = torch.max(test[:,2,:,:,:]).item()\n",
    "    else:\n",
    "        prediction = np.max(np.ma.masked_array(test[:,2,:,:,:], mask=class_2_mask))\n",
    "    \n",
    "    unique_values = torch.unique(prediction_1)\n",
    "    predicted_class = 1 if 2 in unique_values else 0\n",
    "    \n",
    "    return predicted_class, prediction, ground_truth\n",
    "\n",
    "def computeROC(predictions):\n",
    "    from sklearn.metrics import roc_curve, auc # roc curve tools\n",
    "    \n",
    "    g_truths = []\n",
    "    preds = []\n",
    "    for prediction in predictions:\n",
    "        _, predict, ground_truth = get_classification_info(prediction)\n",
    "        g_truths.extend(ground_truth)\n",
    "        preds.append(predict)\n",
    "\n",
    "    preds = np.asarray(preds)\n",
    "    ground_truth = np.asarray(g_truths)\n",
    "    fpr, tpr, _ = roc_curve(g_truths, preds)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhnD1E-uGr8c"
   },
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 0\n",
    "IMG_SIZE = (96,96,96)\n",
    "VAL_SIZE = (256,256,256)\n",
    "SAVE_PATH = \"lightning_logs/\"\n",
    "run_idx = len(os.listdir(\"wandb\"))\n",
    "RUN_NAME = f\"Predict_Segmentation_VI_{run_idx+1}\"\n",
    "pytorch_lightning.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, name):\n",
    "    file_path = \"checkpoints/\"\n",
    "    if not os.path.exists(file_path): \n",
    "        os.makedirs(file_path)\n",
    "    epoch = state[\"epoch\"]\n",
    "    save_dir = file_path + name + str(epoch)\n",
    "    torch.save(state, save_dir)\n",
    "    print(f\"Saving checkpoint for epoch {epoch} in: {save_dir}\")\n",
    "\n",
    "def save_state_dict(state, name):\n",
    "    file_path = \"checkpoints/\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    save_dir = file_path + f\"{name}_best\"\n",
    "    torch.save(state, save_dir)\n",
    "    print(f\"Best accuracy so far. Saving model to:{save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_and_print:\n",
    "    def __init__(self, run_name, tb_logger=None):\n",
    "        self.tb_logger = tb_logger\n",
    "        self.run_name = run_name\n",
    "        self.str_log = \"run_name\" + \"\\n  \\n\"\n",
    "\n",
    "    def lnp(self, tag):\n",
    "        print(self.run_name, time.asctime(), tag)\n",
    "        self.str_log += str(time.asctime()) + \" \" + str(tag) + \"  \\n\"\n",
    "\n",
    "    def dump_to_tensorboard(self):\n",
    "        if not self.tb_logger:\n",
    "            print(\"No tensorboard logger\")\n",
    "        self.tb_logger.experiment.add_text(\"log\", self.str_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baa54303d5c4e24a8f7f6ded4176b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice loss</td><td>▁▁▁</td></tr><tr><td>lr-SGD</td><td>███▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▃▃▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dice loss</td><td>1.0</td></tr><tr><td>lr-SGD</td><td>0.09982</td></tr><tr><td>trainer/global_step</td><td>135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">Predict_Segmentation_VI_303</strong>: <a href=\"https://wandb.ai/lalvarez/traumaIA/runs/2d1pprju\" target=\"_blank\">https://wandb.ai/lalvarez/traumaIA/runs/2d1pprju</a><br/>Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220629_164440-2d1pprju\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    wandb.finish()\n",
    "except:\n",
    "    print(\"Wandb not initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 Loggers start\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 ts_script: 1656518978.6379073\n"
     ]
    }
   ],
   "source": [
    "lnp = Log_and_print(RUN_NAME)\n",
    "lnp.lnp(\"Loggers start\")\n",
    "lnp.lnp(\"ts_script: \" + str(time.time()))\n",
    "\n",
    "wandb_logger = pytorch_lightning.loggers.WandbLogger(\n",
    "    project=\"traumaIA\",\n",
    "    name=RUN_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 MAIN callbacks\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 checkpoint_dirpath: lightning_logs/checkpoints/\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 checkpoint_filename: lightning_logs_Predict_Segmentation_VI_304_Best\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 checkpoint_dirpath: lightning_logs/checkpoints/\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:38 2022 checkpoint_filename: lightning_logs_Predict_Segmentation_VI_304_Last\n"
     ]
    }
   ],
   "source": [
    "lnp.lnp(\"MAIN callbacks\")\n",
    "l_callbacks = []\n",
    "cbEarlyStopping = pytorch_lightning.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=500, mode=\"max\"\n",
    ")\n",
    "l_callbacks.append(cbEarlyStopping)\n",
    "\n",
    "\n",
    "checkpoint_dirpath = SAVE_PATH + \"checkpoints/\"\n",
    "checkpoint_filename = SAVE_PATH[:-1] + \"_\" + RUN_NAME + \"_Best\"\n",
    "lnp.lnp(\"checkpoint_dirpath: \" + checkpoint_dirpath)\n",
    "lnp.lnp(\"checkpoint_filename: \" + checkpoint_filename)\n",
    "cbModelCheckpoint = pytorch_lightning.callbacks.ModelCheckpoint(\n",
    "    monitor=\"dice_metric_injure\", mode=\"max\", dirpath=checkpoint_dirpath, filename=checkpoint_filename, \n",
    ")\n",
    "l_callbacks.append(cbModelCheckpoint)\n",
    "\n",
    "\n",
    "checkpoint_dirpath = SAVE_PATH + \"checkpoints/\"\n",
    "checkpoint_filename = SAVE_PATH[:-1] + \"_\" + RUN_NAME + \"_Last\"\n",
    "lnp.lnp(\"checkpoint_dirpath: \" + checkpoint_dirpath)\n",
    "lnp.lnp(\"checkpoint_filename: \" + checkpoint_filename)\n",
    "cbModelCheckpointLast = pytorch_lightning.callbacks.ModelCheckpoint(\n",
    "   every_n_epochs = 1, dirpath=checkpoint_dirpath, filename=checkpoint_filename, \n",
    ")\n",
    "l_callbacks.append(cbModelCheckpointLast)\n",
    "\n",
    "l_callbacks.append(PrintTableMetricsCallback())\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "l_callbacks.append(lr_monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:39 2022  Start Trainining process...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.20 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>u:\\lauraalvarez\\traumaAI\\Liver_Segmentation\\wandb\\run-20220629_180939-293nq38l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lalvarez/traumaIA/runs/293nq38l\" target=\"_blank\">Predict_Segmentation_VI_304</a></strong> to <a href=\"https://wandb.ai/lalvarez/traumaIA\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | _model        | UNet       | 1.6 M \n",
      "1 | loss_function | DiceCELoss | 0     \n",
      "---------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.510     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating synthetic data to synthetic_data (this may take a while)\n",
      "Predict_Segmentation_VI_304 Wed Jun 29 18:09:47 2022 Tempdir: synthetic_data\n",
      "len(train_files) 45\n",
      "len(validation files) 5\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint directory \\\\chansey.umcn.nl\\diag\\lauraalvarez\\traumaAI\\Liver_Segmentation\\lightning_logs\\checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2466cf9e6c794defa09eec416bfda31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 28 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "Global seed set to 0\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 28 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 0 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455892051b544633a726071a9a31d1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-01.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5757dab77941fba5c72b5207e76df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 0 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9910e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f511b710b44e21bff6b7edaa7cd993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 1 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9820e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b3b22e71841d0b11f68fd2ace02c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 2 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9730e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91237e6966764d9f841e6c7b518df304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 3 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9640e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810f4952c8348b2be68319ee109551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 4 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9550e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b8cd56394c43a6bd84284f4b9ec667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 5 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9460e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a22c29972cc49bebb6204d9ab8415f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 6 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.9370e-02.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe370a68f0f4d48ba6ba45ad7d6c4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dice_metric_injure│val_loss\n",
      "───────────────────────────\n",
      "0.0│1.415297269821167\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n",
      "0.0│0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch: 7 current injure  dice: 0.0000\n",
      "best mean dice: 0.0000 at epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# initialise the LightningModule\n",
    "lnp.lnp(\" Start Trainining process...\")\n",
    "net = Net(train_img_size=IMG_SIZE, val_img_size=VAL_SIZE, n_output=1)#.load_from_checkpoint(\"lightning_logs/checkpoints/lightning_logs_Predict_Segmentation_222_Last.ckpt\", train_img_size=IMG_SIZE, val_img_size=VAL_SIZE, n_output=3)\n",
    "wandb_logger.watch(net)\n",
    "\n",
    "# set up loggers and checkpoints\n",
    "log_dir = os.path.join(root_dir, \"logs\")\n",
    "\n",
    "# initialise Lightning's trainer.\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    default_root_dir=\"lightning_logs/checkpoints\",\n",
    "    gpus=[0],\n",
    "    max_epochs=1000,\n",
    "    # fast_dev_run=True,\n",
    "    auto_lr_find=False,\n",
    "    logger=wandb_logger,\n",
    "    enable_checkpointing=True,\n",
    "    num_sanity_val_steps=1,\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=l_callbacks,\n",
    ")\n",
    "\n",
    "# train\n",
    "result_pred2 = trainer.fit(net)\n",
    "wandb.alert(\n",
    "    title=\"Train finished\",\n",
    "    text=\"The train has finished\"\n",
    ")\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(net.tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Net(train_img_size=IMG_SIZE, val_img_size=VAL_SIZE, n_output=3).load_from_checkpoint(\"lightning_logs/checkpoints/lightning_logs_Predict_Segmentation_168_Best.ckpt\", train_img_size=IMG_SIZE, val_img_size=VAL_SIZE, n_output=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pytorch_lightning.Trainer(\n",
    "#     default_root_dir=\"lightning_logs/checkpoints\",\n",
    "#     gpus=[0],\n",
    "#     max_epochs=1000,\n",
    "#     auto_lr_find=False,\n",
    "#     logger=wandb_logger,\n",
    "#     enable_checkpointing=True,\n",
    "#     num_sanity_val_steps=0,\n",
    "#     log_every_n_steps=1,\n",
    "#     callbacks=l_callbacks,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = trainer.predict(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_pred = Compose([EnsureType(), AsDiscrete(argmax=True),KeepLargestConnectedComponent([1,2], is_onehot=False, independent=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_one = [post_pred(i) for i in decollate_batch(predictions[1][\"prediction\"][\"output\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _save_gif(volume, filename):\n",
    "#     volume = volume.astype(np.float64) / np.max(volume) # normalize the data to 0 - 1\n",
    "#     volume = 255 * volume # Now scale by 255\n",
    "#     volume = volume.astype(np.uint8)\n",
    "#     path_to_gif = os.path.join(\"gifs\", f'{filename}.gif')\n",
    "#     if not os.path.exists(\"gifs\"):\n",
    "#         print(\"Creating gifs directory\")\n",
    "#         os.mkdir(\"gifs\")\n",
    "#     imageio.mimsave(path_to_gif, volume)\n",
    "#     return path_to_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _save_gif(output_one[0].permute(3,1,2,0).cpu().numpy(), \"test-after\")\n",
    "# _save_gif(predictions[1][\"prediction\"][\"output\"][0].permute(3,1,2,0).cpu().numpy(), \"test-before\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests Gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = predictions[1][\"prediction\"]\n",
    "# selected = {\"output\":  output_one[0], \"image\": prediction[\"image\"][0], \"label\": prediction[\"label\"][0]}\n",
    "# selected = Resized(keys=[\"image\", \"label\"], spatial_size=(160, 160, 160))(selected)\n",
    "# selected = Resized(keys=[\"output\"], spatial_size=(160, 160, 160))(selected)\n",
    "# selected = {\"output\": selected[\"output\"].unsqueeze(0), \"image\": selected[\"image\"].unsqueeze(0), \"label\": selected[\"label\"].unsqueeze(0)}\n",
    "# # print('true label:', selected['label'].shape)\n",
    "# pred = selected[\"output\"][0].detach().cpu().numpy()\n",
    "# true_label = selected['label'][0].detach().cpu().numpy()\n",
    "# image = selected['image'][0].cpu().numpy()\n",
    "# # print('true label:', true_label.shape)\n",
    "\n",
    "# blended_true_label = blend_images(image, true_label, alpha=0.3)\n",
    "# blended_final_true_label = torch.from_numpy(blended_true_label).permute(1,2,0,3)\n",
    "\n",
    "# blended_prediction = blend_images(image, pred, alpha=0.3)\n",
    "# blended_final_prediction = torch.from_numpy(blended_prediction).permute(1,2,0,3)\n",
    "\n",
    "# volume_pred = blended_final_prediction[:,:,:,:]\n",
    "# volume_label = blended_final_true_label[:,:,:,:]\n",
    "# volume_pred = np.squeeze(volume_pred).permute(3,0,1,2).cpu()\n",
    "# volume_label = np.squeeze(volume_label).permute(3,0,1,2).cpu()\n",
    "# volume_img = torch.tensor(image).permute(3,1,2,0).repeat(1,1,1,3).cpu()\n",
    "\n",
    "# volume = torch.hstack((volume_img, volume_pred, volume_label))\n",
    "\n",
    "# volume_path = _save_gif(volume.numpy(), f\"blended-test-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = predictions[1][\"prediction\"]\n",
    "\n",
    "# selected = {\"output\": prediction[\"output\"][0], \"image\": prediction[\"image\"][0], \"label\": prediction[\"label\"][0]}\n",
    "# selected = Resized(keys=[\"image\", \"label\"], spatial_size=(160, 160, 160))(selected)\n",
    "# selected = Resized(keys=[\"output\"], spatial_size=(160, 160, 160))(selected)\n",
    "# selected = {\"output\": torch.argmax(selected[\"output\"], 0).unsqueeze(0), \"image\": selected[\"image\"].unsqueeze(0), \"label\": selected[\"label\"].unsqueeze(0)}\n",
    "\n",
    "# pred = selected[\"output\"].detach().cpu().numpy()\n",
    "# true_label = selected['label'][0].detach().cpu().numpy()\n",
    "# image = selected['image'][0].cpu().numpy()\n",
    "\n",
    "# blended_true_label = blend_images(image, true_label, alpha=0.3)\n",
    "# blended_final_true_label = torch.from_numpy(blended_true_label).permute(1,2,0,3)\n",
    "\n",
    "# blended_prediction = blend_images(image, pred, alpha=0.3)\n",
    "# blended_final_prediction = torch.from_numpy(blended_prediction).permute(1,2,0,3)\n",
    "\n",
    "# volume_pred = blended_final_prediction[:,:,:,:]\n",
    "# volume_label = blended_final_true_label[:,:,:,:]\n",
    "# volume_pred = np.squeeze(volume_pred).permute(3,0,1,2).cpu()\n",
    "# volume_label = np.squeeze(volume_label).permute(3,0,1,2).cpu()\n",
    "# volume_img = torch.tensor(image).permute(3,1,2,0).repeat(1,1,1,3).cpu()\n",
    "\n",
    "# volume = torch.hstack((volume_img, volume_pred, volume_label))\n",
    "\n",
    "# volume_path = _save_gif(volume.numpy(), f\"blended-test-1-org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(SAVE_PATH[:-1] + \"_\" + RUN_NAME + \"_Last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_PATH[:-1] + \"_\" + RUN_NAME + \"Last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "spleen_segmentation_3d_lightning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_trauma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f756ff16342a8157e6f46b879d688029dcc5bc6cd621b2b84934bbdd850a743a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
