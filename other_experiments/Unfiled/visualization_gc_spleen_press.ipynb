{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No audio backend is available.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    AsChannelLastd,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    CropForeground,\n",
    "    SpatialCropd,\n",
    "    AsDiscreted,\n",
    "    ScaleIntensityRanged,\n",
    "    LabelToContour\n",
    ")\n",
    "from monai.transforms.transform import MapTransform\n",
    "from monai.transforms.inverse import InvertibleTransform\n",
    "from monai.data import decollate_batch\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import itk\n",
    "\n",
    "from monai.config import DtypeLike, KeysCollection\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "from typing import Any, Dict, Hashable, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "\n",
    "from monai.visualize import matshow3d, blend_images\n",
    "import torch\n",
    "import cv2\n",
    "import imageio\n",
    "from collections import Counter\n",
    "from skimage.segmentation import (morphological_chan_vese,\n",
    "                                  morphological_geodesic_active_contour,\n",
    "                                  inverse_gaussian_gradient, expand_labels)\n",
    "from skimage.morphology import disk, dilation, binary_dilation, ball, cube, closing , disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveDicts(MapTransform, InvertibleTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            self.push_transform(d, key)\n",
    "\n",
    "        a = {}\n",
    "        for key in self.key_iterator(d):\n",
    "            a[key] = d[key]\n",
    "            if key == \"image\":\n",
    "                a[\"path\"] = d[\"image_meta_dict\"][\"filename_or_obj\"]\n",
    "        if a.get(\"path\", None) is None:\n",
    "            a[\"path\"] = d[\"label_meta_dict\"][\"filename_or_obj\"]\n",
    "\n",
    "        # a = {\"image\": d[\"image\"], \"label\": d[\"label\"], \"label-gc\":  d[\"label-gc\"] , \"path\": d[\"image_meta_dict\"][\"filename_or_obj\"]}\n",
    "\n",
    "        # print(a[\"path\"])\n",
    "        d = a\n",
    "        return d\n",
    "\n",
    "    def inverse(self, data: Mapping[Hashable, Any]) -> Dict[Hashable, Any]:\n",
    "        d = deepcopy(dict(data))\n",
    "        for key in self.key_iterator(d):\n",
    "            d[key] = d[key]\n",
    "            # Remove the applied transform\n",
    "            self.pop_transform(d, key)\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms.intensity.array import ScaleIntensityRangePercentiles\n",
    "\n",
    "\n",
    "class ScaleIntensityRangePercentilesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Dictionary-based wrapper of :py:class:`monai.transforms.ScaleIntensityRangePercentiles`.\n",
    "\n",
    "    Args:\n",
    "        keys: keys of the corresponding items to be transformed.\n",
    "            See also: monai.transforms.MapTransform\n",
    "        lower: lower percentile.\n",
    "        upper: upper percentile.\n",
    "        b_min: intensity target range min.\n",
    "        b_max: intensity target range max.\n",
    "        clip: whether to perform clip after scaling.\n",
    "        relative: whether to scale to the corresponding percentiles of [b_min, b_max]\n",
    "        channel_wise: if True, compute intensity percentile and normalize every channel separately.\n",
    "            default to False.\n",
    "        dtype: output data type, if None, same as input image. defaults to float32.\n",
    "        allow_missing_keys: don't raise exception if key is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    backend = ScaleIntensityRangePercentiles.backend\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        lower: float,\n",
    "        upper: float,\n",
    "        b_min: Optional[float],\n",
    "        b_max: Optional[float],\n",
    "        clip: bool = False,\n",
    "        relative: bool = False,\n",
    "        channel_wise: bool = False,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.scaler = ScaleIntensityRangePercentiles(\n",
    "            lower, upper, b_min, b_max, clip, relative, channel_wise, dtype\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            d[key] = self.scaler(d[key])\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNUnetScaleIntensity(MapTransform):\n",
    "    \"\"\"\n",
    "    Dictionary-based wrapper of :py:class:`monai.transforms.ScaleIntensityRange`.\n",
    "\n",
    "    Args:\n",
    "        keys: keys of the corresponding items to be transformed.\n",
    "            See also: monai.transforms.MapTransform\n",
    "        a_min: intensity original range min.\n",
    "        a_max: intensity original range max.\n",
    "        b_min: intensity target range min.\n",
    "        b_max: intensity target range max.\n",
    "        clip: whether to perform clip after scaling.\n",
    "        dtype: output data type, if None, same as input image. defaults to float32.\n",
    "        allow_missing_keys: don't raise exception if key is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    def _compute_stats(self, volume, mask):\n",
    "        print(volume.shape)\n",
    "        print(mask.shape)\n",
    "        volume = np.ma.masked_equal(volume.copy().astype(np.int16) * np.greater(mask, 0), 0).compressed()\n",
    "        median = np.median(volume)\n",
    "        mean = np.mean(volume)\n",
    "        std = np.std(volume)\n",
    "        mn = np.min(volume)\n",
    "        mx = np.max(volume)\n",
    "        percentile_99_5 = np.percentile(volume, 99.5)\n",
    "        percentile_00_5 = np.percentile(volume, 00.5)\n",
    "        print(median, mean, std, mn, mx, percentile_99_5, percentile_00_5)\n",
    "        return median, mean, std, mn, mx, percentile_99_5, percentile_00_5\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            stats = self._compute_stats(d[key], d[\"label\"])\n",
    "            d[key] = np.clip(d[key], stats[6], stats[5])\n",
    "            d[key] = (d[key] - stats[1]) / stats[2]\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WriteToMHA(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        output_dir: str,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            if isinstance(d[key], torch.Tensor):\n",
    "                d[key] = d[key].detach().cpu().numpy().astype(np.int8)\n",
    "            original = sitk.ReadImage(d[\"path\"])\n",
    "            filename = os.path.basename(d[\"path\"]).split(\".\")[0] + \".mha\"\n",
    "            save_dir = os.path.join(self.output_dir, filename)\n",
    "            if not os.path.exists(os.path.dirname(save_dir)):\n",
    "                print(f\"Creating directory: {os.path.dirname(save_dir)}\")\n",
    "                os.makedirs(os.path.dirname(save_dir))\n",
    "            print(f\"Saving to {save_dir}\")\n",
    "            img = sitk.GetImageFromArray(d[key])\n",
    "            img.SetSpacing(original.GetSpacing())\n",
    "            img.SetOrigin(original.GetOrigin())\n",
    "            sitk.WriteImage(img, save_dir)\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class CreateSyntheticLabel(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        threshold: float = 0.5,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        print(d[\"label\"].shape) # (1, 6, 512, 512, 199)\n",
    "        d[\"label\"] = d[\"label\"].squeeze() # (6, 512, 512, 199))\n",
    "        old_mask = d[\"label\"][3, :, :, :].unsqueeze(0).numpy().copy() # (1, 512, 512, 199)\n",
    "        # histogram, bin_edges = np.histogram(old_mask.flatten(), bins=256, range=(0, 1))\n",
    "\n",
    "        # # configure and draw the histogram figure\n",
    "        # plt.figure()\n",
    "        # plt.title(\"Grayscale Histogram\")\n",
    "        # plt.xlabel(\"grayscale value\")\n",
    "        # plt.ylabel(\"pixel count\")\n",
    "        # plt.xlim([0.0, 1.0])  # <- named arguments do not work here\n",
    "\n",
    "        # plt.plot(bin_edges[0:-1], histogram)  # <- or here\n",
    "        # plt.show()\n",
    "        new_mask = np.zeros_like(old_mask) # (1, 512, 512, 199)\n",
    "        new_img = d[\"image\"][:, :, :, :].numpy().copy()\n",
    "        idx_label = np.where(old_mask.flatten() == 1)[0]\n",
    "        idx_img = np.where(new_img.flatten() > self.threshold)[0]\n",
    "        idx_to_change = np.intersect1d(idx_img, idx_label)\n",
    "        np.put(new_mask, idx_to_change, 1)\n",
    "        old_mask -= new_mask\n",
    "\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        closed_slices = list()\n",
    "        for slice in range(new_mask.shape[-1]):\n",
    "            result = cv2.morphologyEx(\n",
    "                new_mask[0, :, :, slice], cv2.MORPH_CLOSE, kernel, iterations=4\n",
    "            )\n",
    "            result = cv2.medianBlur(result, 9)\n",
    "            closed_slices.append(result)\n",
    "\n",
    "        new_mask = np.stack(closed_slices)\n",
    "\n",
    "        if len (new_mask.shape) > 3: \n",
    "            new_mask = torch.Tensor(new_mask[0])\n",
    "            old_mask = torch.Tensor(old_mask[0])\n",
    "        else:\n",
    "            new_mask = torch.Tensor(new_mask).permute(1, 2, 0)\n",
    "            old_mask = torch.Tensor(old_mask[0])\n",
    "        \n",
    "        print(old_mask.shape, new_mask.shape) # (1, 512, 512, 199) (1, 512, 512, 199)\n",
    "        print(d[\"label\"].shape) # (6, 512, 512, 199)\n",
    "\n",
    "        d[\"label\"][1, :, :, :] = torch.Tensor(new_mask) \n",
    "        d[\"label\"][3, :, :, :] = torch.Tensor(old_mask)\n",
    "        d[\"label\"] = d[\"label\"].unsqueeze(0)\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGCLabel(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        threshold: float = 0.5,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "\n",
    "        d = dict(data)\n",
    "        print(d[\"label\"].shape, d[\"label-gc\"].shape)\n",
    "        spleen_channel = np.where((d[\"label-gc\"] != 1), 0, d[\"label-gc\"])\n",
    "        spleen_channel = np.where((spleen_channel == 1), 1, spleen_channel)\n",
    "        print(d[\"label\"].shape, d[\"label-gc\"].shape)\n",
    "        d[\"label\"][1, :, :, :] = (\n",
    "            torch.Tensor(spleen_channel).unsqueeze(0) - d[\"label\"][3, :, :, :]\n",
    "        )\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsDiscrete1sd(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "\n",
    "        d = data\n",
    "        d[\"label\"] = d[\"label\"].astype(np.int8)\n",
    "        back = np.expand_dims(np.zeros(d[\"label\"][0, :, :, :].shape, dtype=np.int8), 0)\n",
    "        d[\"label\"] = torch.Tensor(np.append(back, d[\"label\"], axis=0))\n",
    "        print(d[\"label\"].shape)\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveBackgroundd(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "\n",
    "        d = data\n",
    "        print(\"before: \", d[\"label\"].shape)\n",
    "        d[\"label\"] = d[\"label\"][1:, :, :, :]\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DilationLabel(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def dilatation():\n",
    "                    # if ORGAN == \"Spleen\":\n",
    "            #     injury_size = np.sum(old_mask_injury)/2\n",
    "            #     if injury_size < 4500:\n",
    "            #         # radius = int((injury_size/1000)*2)\n",
    "            #         old_mask_organ = np.where((img != 1), 0, img)\n",
    "            #         final_mask_injury = dilation(old_mask_injury[0,:,:,:], footprint=ball(radius=6))\n",
    "            #         final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "            #         final_mask = old_mask_organ + final_mask_injury\n",
    "            #         final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "            #         d[\"label\"] = final_mask\n",
    "            #     else:\n",
    "            #         old_mask_organ = np.where((img != 1), 0, img)\n",
    "            #         final_mask_injury = dilation(old_mask_injury[0,:,:,:], footprint=ball(radius=2))\n",
    "            #         final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "            #         final_mask = old_mask_organ + final_mask_injury\n",
    "            #         final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "            #         d[\"label\"] = final_mask\n",
    "            # if ORGAN == \"Liver\":\n",
    "            #     old_mask_organ = np.where((img != 1), 0, img)\n",
    "            #     mask = disk(2)\n",
    "            #     new_mask_injury = list()\n",
    "            #     for slice in range(old_mask_injury.shape[1]):\n",
    "            #         result = dilation(old_mask_injury[0,slice,:,:], footprint=mask)\n",
    "            #         new_mask_injury.append(result)\n",
    "            #     final_mask_injury = np.stack(new_mask_injury)\n",
    "            #     final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "            #     final_mask = old_mask_organ + final_mask_injury\n",
    "            #     final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "            #     d[\"label\"] = final_mask\n",
    "            pass\n",
    "\n",
    "    def store_evolution_in(lst):\n",
    "        \"\"\"Returns a callback function to store the evolution of the level sets in\n",
    "        the given list.\n",
    "        \"\"\"\n",
    "        def _store(x):\n",
    "            lst.append(np.copy(x))\n",
    "        return _store\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        init_label = d[\"label\"].squeeze() #antes img\n",
    "        old_mask_injury = np.where((init_label != 2), 0, init_label) # save only the injury\n",
    "        scanner = d[\"image\"].squeeze()\n",
    "        old_mask_organ = np.where((init_label != 1), 0, init_label)\n",
    "        gimage = inverse_gaussian_gradient(scanner)\n",
    "        cropped_injury = CropForegroundd(keys=[\"image\", \"label\"], \n",
    "                            source_key=\"label\",\n",
    "                            margin=30)({\"image\": np.expand_dims(gimage,0), \"label\": np.expand_dims(old_mask_injury,0)})\n",
    "        # evolution = [] \n",
    "        # # callback = store_evolution_in(evolution)\n",
    "        ls = morphological_geodesic_active_contour(cropped_injury[\"image\"][0], num_iter=1, #1000 advised?\n",
    "                                                init_level_set=cropped_injury[\"label\"][0],\n",
    "                                                smoothing=1, balloon=0,\n",
    "                                                threshold=0.2)\n",
    "        # ls = morphological_chan_vese(cropped_injury[\"image\"][0], num_iter=25, #1000 advised?\n",
    "        #                                         init_level_set=cropped_injury[\"label\"][0])\n",
    "                                                # iter_callback=callback)\n",
    "        from monai.data import MetaTensor\n",
    "        cropped_injury[\"label\"] = MetaTensor(torch.tensor(np.expand_dims(ls,0)), meta=cropped_injury[\"label\"].meta, applied_operations = cropped_injury[\"label\"].applied_operations )\n",
    "        inv_cropped = CropForegroundd(keys=[\"image\", \"label\"], source_key=\"label\",\n",
    "                                            margin=30).inverse(cropped_injury)\n",
    "        final_mask = old_mask_organ + inv_cropped[\"label\"]\n",
    "        d[\"label\"] =  final_mask\n",
    "\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antiguo NO BORRAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets.widgets import *\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "injure_liver = os.path.join(\n",
    "    \"/Volumes/diag/\",\n",
    "    \"lauraalvarez\",\n",
    "    \"data\",\n",
    "    \"nnUNet_raw_data_base\",\n",
    "    \"nnUNet_raw_data\",\n",
    "    \"Task504_LiverTrauma\",\n",
    "    \"imagesTr\",\n",
    "    \"TRMLIV_000_0000.nii.gz\",\n",
    ")\n",
    "injure_liver_label = os.path.join(\n",
    "    \"/mnt/chansey/\",\n",
    "    \"lauraalvarez\",\n",
    "    \"nnunet\",\n",
    "    \"nnUNet_raw_data_base\",\n",
    "    \"nnUNet_raw_data\",\n",
    "    \"Task504_LiverTrauma\",\n",
    "    \"labelsTr\",\n",
    "    \"TRMLIV_000.nii.gz\",\n",
    ")\n",
    "\n",
    "spleen_error_img = os.path.join(\n",
    "    \"U:\\\\\", \"lauraalvarez\", \"nnunet\", \"nnUNet_raw_data\", \"Task504_LiverTrauma\", \"imagesTs\", \"TRMLIV_000_0000.nii.gz\"\n",
    ")\n",
    "spleen_error_msk = os.path.join(  \"U:\\\\\", \"lauraalvarez\", \"nnunet\", \"nnUNet_raw_data\", \"Task504_LiverTrauma\", \"out\", \"TRMLIV_000.nii.gz\")\n",
    "spleen_error_true = os.path.join(\n",
    "    \"U:\\\\\", \"lauraalvarez\", \"nnunet\", \"nnUNet_raw_data\", \"Task504_LiverTrauma\", \"labelsTs\", \"TRMLIV_000.nii.gz\"\n",
    ")\n",
    "\n",
    "# spleen_error_img = os.path.join(\n",
    "#     \"/mnt/chansey/\", \"lauraalvarez\", \"data\", \"liver\", \"train\", \"data\", \"L110086.mha\"\n",
    "# )\n",
    "# spleen_error_msk = os.path.join(  \"/mnt/chansey/\", \"lauraalvarez\", \"data\", \"liver\", \"train\", \"mask\", \"L110086.mha\")\n",
    "# spleen_error_msk = os.path.join(\n",
    "#     \"/mnt/chansey/\",\n",
    "#     \"lauraalvarez\",\n",
    "#     \"data\",\n",
    "#     \"_overlays_from_alessa\",\n",
    "#     \"overlays\",\n",
    "#     \"overlay_B2\",\n",
    "#     \"L110027.mha\",\n",
    "# )\n",
    "# gc_msk = os.path.join(\"/mnt/chansey/\", \"lauraalvarez\", \"data\", \"liver\")\n",
    "\n",
    "selected_img = spleen_error_img\n",
    "selected_msk = spleen_error_msk\n",
    "selected_true = spleen_error_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x0000019634C18910>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\nibabel\\loadsave.py:90\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     stat_result \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(filename)\n\u001b[0;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'U:\\\\lauraalvarez\\\\nnunet\\\\nnUNet_raw_data\\\\Task504_LiverTrauma\\\\out\\\\TRMLIV_000.nii.gz'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:90\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[39mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data]\n\u001b[1;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items)\n\u001b[0;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:54\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m transform(\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m transform(parameters)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\io\\dictionary.py:133\u001b[0m, in \u001b[0;36mLoadImaged.__call__\u001b[1;34m(self, data, reader)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mfor\u001b[39;00m key, meta_key, meta_key_postfix \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_iterator(d, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_keys, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_key_postfix):\n\u001b[1;32m--> 133\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loader(d[key], reader)\n\u001b[0;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loader\u001b[39m.\u001b[39mimage_only:\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\io\\array.py:226\u001b[0m, in \u001b[0;36mLoadImage.__call__\u001b[1;34m(self, filename, reader)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mif\u001b[39;00m reader\u001b[39m.\u001b[39mverify_suffix(filename):\n\u001b[1;32m--> 226\u001b[0m     img \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mread(filename)\n\u001b[0;32m    227\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\data\\image_reader.py:906\u001b[0m, in \u001b[0;36mNibabelReader.read\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m filenames:\n\u001b[1;32m--> 906\u001b[0m     img \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mload(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_)\n\u001b[0;32m    907\u001b[0m     img \u001b[39m=\u001b[39m correct_nifti_header_if_necessary(img)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\nibabel\\loadsave.py:92\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such file or no access: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m stat_result\u001b[39m.\u001b[39mst_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task504_LiverTrauma\\out\\TRMLIV_000.nii.gz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mu:\\lauraalvarez\\traumaAI\\Liver_Segmentation\\visualization_gc_spleen_pres.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# val_transforms_overlays_float_class = Compose(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#     [\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#         LoadImaged(keys=[\"label\"]),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     ]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m val_transforms_synthetic_spleen \u001b[39m=\u001b[39m Compose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     [\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         LoadImaged(keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m injures \u001b[39m=\u001b[39m normal_plot(paths)\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(injures[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y535sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mprint\u001b[39m(injures[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\compose.py:173\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, input_):\n\u001b[0;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m _transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m--> 173\u001b[0m         input_ \u001b[39m=\u001b[39m apply_transform(_transform, input_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap_items, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munpack_items, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_stats)\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m input_\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:114\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         _log_stats(data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplying transform \u001b[39m\u001b[39m{\u001b[39;00mtransform\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x0000019634C18910>"
     ]
    }
   ],
   "source": [
    "paths = {\"label\": selected_msk, \"image\": selected_img, \"tLabel\": selected_true}\n",
    "normal_plot = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\",\"label\",\"tLabel\"]),\n",
    "        AsChannelFirstd(keys=[\"image\",\"label\",\"tLabel\"]),\n",
    "        AddChanneld(keys=[\"label\",\"image\", \"tLabel\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\", ], axcodes=\"RAS\"),\n",
    "        NNUnetScaleIntensity(keys=[\"image\"]),\n",
    "        # Resized(keys=[\"image\",\"label\"], spatial_size=(160,160,160)),\n",
    "    ]\n",
    ")\n",
    "# val_transforms_overlays_float_class = Compose(\n",
    "#     [\n",
    "#         LoadImaged(keys=[\"label\"]),\n",
    "#         RemoveDicts(keys=[\"label\"]),\n",
    "#         AsChannelFirstd(keys=[\"label\"]),\n",
    "#         AsDiscrete1sd(keys=[\"label\"]),\n",
    "#         AsDiscreted(keys=[\"label\"], argmax=True, to_onehot=7),\n",
    "#         RemoveBackgroundd(keys=[\"label\"]),\n",
    "#         WriteToMHA(\n",
    "#             keys=[\"label\"],\n",
    "#             output_dir=\"/mnt/chansey/lauraalvarez/data/spleen/synthetic_overlays\",\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# val_transforms_insert_gc_overlay = Compose( #igual no es asi\n",
    "#     [\n",
    "#         LoadImaged(keys=[\"image\", \"label\", \"label-gc\"]),\n",
    "#         RemoveDicts(keys=[\"image\", \"label\", \"label-gc\"]),\n",
    "#         adaptOverlay(keys=[\"label-gc\"]),\n",
    "#         AsChannelFirstd(keys=[\"label\", \"label-gc\"]),\n",
    "#         AddGCLabel(keys=[\"label\"]),\n",
    "#         WriteToMHA(keys=[\"label\"], output_dir=\"/mnt/chansey/lauraalvarez/data/spleen/synthetic_overlays\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "val_transforms_synthetic_spleen = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        RemoveDicts(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\"]),\n",
    "        AsChannelFirstd(keys=[\"label\"]),\n",
    "        NNUnetScaleIntensity(keys=[\"image\"]),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "        CreateSyntheticLabel(keys=[\"label\"], threshold=0.5),\n",
    "        # Resized(keys=[\"image\", \"label\"], spatial_size=(259, 259, 259))\n",
    "        WriteToMHA(\n",
    "            keys=[\"label\"],\n",
    "            output_dir=\"/mnt/chansey/lauraalvarez/data/spleen/synthetic_overlays\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "injures = normal_plot(paths)\n",
    "\n",
    "print(injures[\"label\"].shape)\n",
    "print(injures[\"image\"].shape)\n",
    "# print(np.unique(injures[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 160, 160, 160)\n",
      "(1, 160, 160, 160)\n"
     ]
    }
   ],
   "source": [
    "inj =  dict(injures)\n",
    "inj =Resized(keys=[\"image\", \"label\", \"tLabel\"], spatial_size=(160, 160, 160))(inj)\n",
    "# injures[\"label\"] = np.expand_dims(injures[\"label\"],0)\n",
    "# injures[\"image\"] = np.expand_dims(injures[\"image\"],0)\n",
    "print(inj[\"label\"].shape)\n",
    "print(inj[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pred_blending = Compose([AsDiscrete(argmax=True)])\n",
    "injures_one_channel = post_pred_blending(injures[\"label\"])\n",
    "blended_label_in = blend_images(\n",
    "    inj[\"image\"], inj[\"label\"], 0.5\n",
    ")\n",
    "blended_final = torch.from_numpy(blended_label_in).permute(1, 2, 0, 3)\n",
    "\n",
    "blended_true_label = blend_images(inj[\"image\"], inj[\"tLabel\"], 0.5)\n",
    "blended_true_label = torch.from_numpy(blended_true_label).permute(1, 2, 0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 160, 3, 160])\n",
      "torch.Size([160, 160, 3, 160])\n"
     ]
    }
   ],
   "source": [
    "print(torch.from_numpy(inj[\"image\"]).permute(1,2,0,3).repeat(1,1,3,1).shape)\n",
    "print(blended_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 480, 3, 160])\n",
      "torch.Size([160, 480, 160, 3])\n"
     ]
    }
   ],
   "source": [
    "volume = torch.hstack((torch.from_numpy(inj[\"image\"]).permute(1,2,0,3).repeat(1,1,3,1), blended_final, blended_true_label))\n",
    "print(volume.shape)\n",
    "volume = volume.permute(0,1,3,2)\n",
    "print(volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "def _save_gif(volume, filename):\n",
    "    volume = volume.astype(np.float64) / np.max(volume) # normalize the data to 0 - 1\n",
    "    volume = volume *255 # Now scale by 255\n",
    "    volume = volume.astype(np.uint8)\n",
    "    path_to_gif = os.path.join(\"gifs\", f'{filename}.gif')\n",
    "    if not os.path.exists(\"gifs\"):\n",
    "        print(\"Creating gifs directory\")\n",
    "        os.mkdir(\"gifs\")\n",
    "    imageio.mimsave(path_to_gif, volume)\n",
    "    return path_to_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_path = _save_gif(blended_final.numpy().transpose(0,1,3,2), f\"blended-test-11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09df06a12bbf4c3a8d7f16e8c32a6a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=79, description='slice', max=159), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dicom_animation(slice):\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(20, 20))\n",
    "    plt.title(f\"liver no injured \")\n",
    "    axarr[0].imshow(blended_final[:, :, :, slice])\n",
    "    axarr[1].imshow(blended_true_label[:, :, :, slice])\n",
    "    axarr[2].imshow(inj[\"image\"][0, :, :, slice], cmap=\"bone\")\n",
    "    # axarr[2].imshow(new_mask[0, :, :, slice])\n",
    "    # axarr[1].imshow(injures[\"label\"][1, :, :, slice], cmap=\"bone\")\n",
    "\n",
    "\n",
    "interact(dicom_animation, slice=(0, inj[\"label\"].shape[-1] - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select pixels of injury mask\n",
    "injury_mask = injures[\"label\"][3, :, :, :]\n",
    "values = injures[\"image\"][0, :, :, :][injury_mask == 1]\n",
    "histogram, bin_edges = np.histogram(values, bins=256, range=(0, 1))\n",
    "\n",
    "# configure and draw the histogram figure\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([0.0, 1.0])  # <- named arguments do not work here\n",
    "\n",
    "plt.plot(bin_edges[0:-1], histogram)  # <- or here\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_transforms_synthetic_spleen = Compose(\n",
    "#     [\n",
    "#         LoadImaged(keys=[\"image\", \"label\"]),\n",
    "#         # RemoveDicts(keys=[\"image\", \"label\"]),\n",
    "#         # AddChanneld(keys=[\"image\"]),\n",
    "#         # AsChannelFirstd(keys=[\"label\"]),\n",
    "#         # NNUnetScaleIntensity(keys=[\"image\"]),\n",
    "#         # ToTensord(keys=[\"image\", \"label\"]),\n",
    "#         # CreateSyntheticLabel(keys=[\"label\"], threshold=0.5),\n",
    "#         # Resized(keys=[\"image\", \"label\"], spatial_size=(259, 259, 259))\n",
    "#         # WriteToMHA(\n",
    "#         #     keys=[\"label\"],\n",
    "#         #     output_dir=\"/mnt/chansey/lauraalvarez/data/spleen/synthetic_overlays\",\n",
    "#         # ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# final_result = val_transforms_synthetic_spleen([{\"image\": path_img, \"label\": path_synth_label }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimpleITK import GetArrayFromImage, ReadImage\n",
    "\n",
    "HOME = \"U:\\\\\"\n",
    "path_synth_label = os.path.join(HOME, \"lauraalvarez\", \"data\",\"synthetic_overlays\",\"M110074.mha\")\n",
    "path_img = os.path.join(HOME, \"lauraalvarez\", \"data\",\"spleen\",\"imagesTs\", \"M110040.mha\")\n",
    "path_label = os.path.join(HOME, \"lauraalvarez\", \"data\",\"_overlays_from_alessa\",\"overlay_june9_v2\", \"overlay\", \"M110040.mha\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"U:\\lauraalvarez\\data\\_overlays_from_alessa\\overlay_june9_v2\\overlay\\M110040.mha\"\n",
    "# \"U:\\lauraalvarez\\data\\_original_full_dataset\\mask\\M110074.mha\"\n",
    "\n",
    "# data = {\"image\": ReadImage(path_img) , \"label\": ReadImage(path_label)}\n",
    "\n",
    "# data[\"image\"] = sitk.DICOMOrient(data[\"image\"], 'LAS')\n",
    "# data[\"label\"] = sitk.DICOMOrient(data[\"label\"], 'RAS')\n",
    "\n",
    "# # data[\"image\"].GetDirection(), data[\"label\"].GetDirection()\n",
    "\n",
    "# data = {\"image\": GetArrayFromImage(data[\"image\"]) , \"label\": GetArrayFromImage(data[\"label\"])}\n",
    "\n",
    "# print(data[\"label\"].shape , data[\"image\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 512, 512, 1441)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "applying transform <__main__.CreateSyntheticLabel object at 0x0000029160E78520>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:89\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m map_items:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:89\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m map_items:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m [_apply_transform(transform, item, unpack_items) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data]\n\u001b[0;32m     90\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_transform(transform, data, unpack_items)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:54\u001b[0m, in \u001b[0;36m_apply_transform\u001b[1;34m(transform, parameters, unpack_parameters)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m transform(\u001b[39m*\u001b[39mparameters)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m transform(parameters)\n",
      "\u001b[1;32mu:\\lauraalvarez\\traumaAI\\Liver_Segmentation\\visualization_gc_spleen_pres.ipynb Cell 24\u001b[0m in \u001b[0;36mCreateSyntheticLabel.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mmorphologyEx(\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     new_mask[\u001b[39m0\u001b[39m, :, :, \u001b[39mslice\u001b[39m], cv2\u001b[39m.\u001b[39mMORPH_CLOSE, kernel, iterations\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m result \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mmedianBlur(result, \u001b[39m9\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m closed_slices\u001b[39m.\u001b[39mappend(result)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:/a/opencv-python/opencv-python/opencv/modules/imgproc/src/median_blur.simd.hpp:985: error: (-215:Assertion failed) src.depth() == CV_8U && (cn == 1 || cn == 3 || cn == 4) in function 'cv::opt_AVX2::medianBlur'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mu:\\lauraalvarez\\traumaAI\\Liver_Segmentation\\visualization_gc_spleen_pres.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m: path_img , \u001b[39m\"\u001b[39m\u001b[39mlabel_0\u001b[39m\u001b[39m\"\u001b[39m: path_label, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: path_label}\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m val_transforms_synthetic_spleen \u001b[39m=\u001b[39m Compose(\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     [\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         LoadImaged(keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabel_0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m final_result \u001b[39m=\u001b[39m val_transforms_synthetic_spleen([data])\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#Y126sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(final_result[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape, final_result[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlabel_0\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape, final_result[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\compose.py:173\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, input_)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, input_):\n\u001b[0;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m _transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m--> 173\u001b[0m         input_ \u001b[39m=\u001b[39m apply_transform(_transform, input_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap_items, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munpack_items, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_stats)\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m input_\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\transform.py:114\u001b[0m, in \u001b[0;36mapply_transform\u001b[1;34m(transform, data, map_items, unpack_items, log_stats)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         _log_stats(data\u001b[39m=\u001b[39mdata)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapplying transform \u001b[39m\u001b[39m{\u001b[39;00mtransform\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: applying transform <__main__.CreateSyntheticLabel object at 0x0000029160E78520>"
     ]
    }
   ],
   "source": [
    "data = {\"image\": path_img , \"label_0\": path_label, \"label\": path_label}\n",
    "\n",
    "val_transforms_synthetic_spleen = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label_0\", \"label\"]),\n",
    "        # RemoveDicts(keys=[\"image\", \"label\"]),\n",
    "        AsChannelFirstd(keys=[\"label_0\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\",  \"label_0\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-175,\n",
    "                    a_max=250,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                ),\n",
    "        CreateSyntheticLabel(keys=[ \"label\"], threshold=0.73),\n",
    "        ToTensord(keys=[\"image\",  \"label_0\", \"label\"]),\n",
    "        # Resized(keys=[\"image\", \"label\"], spatial_size=(259, 259, 259))\n",
    "        # WriteToMHA(\n",
    "        #     keys=[\"label\"],\n",
    "        #     output_dir=\"/mnt/chansey/lauraalvarez/data/spleen/synthetic_overlays\",\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_result = val_transforms_synthetic_spleen([data])\n",
    "\n",
    "print(final_result[0][\"image\"].shape, final_result[0][\"label_0\"].shape, final_result[0][\"label\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1, 512, 512, 1441) torch.Size([6, 512, 512, 1441])\n",
      "shape after argmax label (1, 512, 512, 1441), (1, 512, 512, 1441), (1, 512, 512, 1441)\n",
      "shape after blend torch.Size([512, 512, 3, 1441]) (3, 512, 512, 1441) torch.Size([512, 512, 3, 1441])\n"
     ]
    }
   ],
   "source": [
    "image = final_result[0][\"image\"].numpy()\n",
    "old_spleen_label = final_result[0][\"label_0\"][0] # [:,:,3,:,:]\n",
    "spleen_label =  final_result[0][\"label\"][0] \n",
    "\n",
    "print(\"shape\", image.shape, spleen_label.shape)\n",
    "\n",
    "post_pred_blending = Compose([AsDiscrete(argmax=True)])\n",
    "injures_one_channel = post_pred_blending(spleen_label)\n",
    "old_injures_one_channel =  post_pred_blending(old_spleen_label)\n",
    "\n",
    "print(f\"shape after argmax label {old_injures_one_channel.shape}, {injures_one_channel.shape}, {image.shape}\")\n",
    "\n",
    "blended_label_in = blend_images( image, injures_one_channel.numpy(), 0.5)\n",
    "blended_label_in_0 = blend_images( image, old_injures_one_channel.numpy(), 0.5)\n",
    "blended_final = torch.from_numpy(blended_label_in).permute(1, 2, 0, 3)\n",
    "blended_final_0 = torch.from_numpy(blended_label_in_0).permute(1, 2, 0, 3)\n",
    "\n",
    "# blended_true_label = blend_images(final_result[0][\"image\"], old , 0.5)\n",
    "# blended_true_label = torch.from_numpy(blended_true_label).permute(1, 2, 0, 3)\n",
    "\n",
    "print(\"shape after blend\", blended_final_0.shape, blended_label_in.shape, blended_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 512, 512, 1441), (1, 6, 1441, 512))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spleen_I_label = LabelToContour()(final_result[0][\"label\"][:,:,3,:,:])\n",
    "# spleen_O_label =  LabelToContour()(final_result[0][\"label\"][:,:,1,:,:])\n",
    "# spleen_label = torch.stack((spleen_O_label.flip(2), spleen_I_label.flip(2))).permute(1,2,0,3,4)\n",
    "# old = final_result[0][\"old_label\"][:,:,3,:,:]\n",
    "\n",
    "labels = [1,3]\n",
    "channels = list()\n",
    "for i, channel in enumerate(labels):\n",
    "    c = LabelToContour()(final_result[0][\"label\"][:,:, channel, :, :].flip(2))\n",
    "    c = np.where((c == 1), i + 1, c)\n",
    "    channels.append(c)\n",
    "\n",
    "# we got channels splitted with 1 each. if we add them we should get what we want\n",
    "chans = np.stack(channels, axis=0)\n",
    "spleen_label = np.max(chans, axis=0)\n",
    "spleen_label = torch.from_numpy(spleen_label)\n",
    "\n",
    "spleen_label = (final_result[0][\"label\"][:,:,1,:,:]).flip(2)\n",
    "final_result[0][\"image\"].numpy().shape,  spleen_label.permute(0,1,3,2).numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7135ad17bf4150a76acc81073579fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=720, description='slice', max=1440), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dicom_animation(slice):\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(30, 30))\n",
    "    plt.title(f\"liver no injured \")\n",
    "    axarr[0].imshow(image[0, :, :, slice], cmap=\"bone\")\n",
    "    # axarr[1].imshow(data[\"image\"][0, :, :, slice], cmap=\"bone\")\n",
    "    axarr[1].imshow(blended_final_0[:, :, :, slice],  cmap=\"bone\")\n",
    "    axarr[2].imshow(blended_final[:, :, :, slice],  cmap=\"bone\")\n",
    "    # axarr[1].imshow(injures[\"label\"][1, :, :, slice], cmap=\"bone\")\n",
    "\n",
    "\n",
    "interact(dicom_animation, slice=(0, blended_final.shape[-1] - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38ac894988244a4a148751a9cedc839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=720, description='slice', max=1440), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dicom_animation(slice):\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(30, 30))\n",
    "    plt.title(f\"liver no injured \")\n",
    "    axarr[0].imshow(image[0, :, :, slice], cmap=\"bone\")\n",
    "    # axarr[1].imshow(data[\"image\"][0, :, :, slice], cmap=\"bone\")\n",
    "    axarr[1].imshow(blended_final_0[:, :, :, slice],  cmap=\"bone\")\n",
    "    axarr[2].imshow(blended_final[:, :, :, slice],  cmap=\"bone\")\n",
    "    # axarr[1].imshow(injures[\"label\"][1, :, :, slice], cmap=\"bone\")\n",
    "\n",
    "\n",
    "interact(dicom_animation, slice=(0, blended_final.shape[-1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_000_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_000.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_000.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_001_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_001.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_001.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_002_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_002.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_002.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_003_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_003.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_003.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_004_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_004.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_004.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_005_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_005.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_005.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_006_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_006.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_006.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\imagesTs\\TRMSPL_007_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\out\\TRMSPL_007.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\\labelsTs\\TRMSPL_007.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_000_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_000.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_000.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_001_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_001.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_001.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_002_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_002.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_002.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_003_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_003.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_003.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_004_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_004.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_004.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_005_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_005.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_005.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_006_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_006.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_006.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_007_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_007.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_007.nii.gz\n",
      "Infering for image:U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\imagesTs\\TLIV_008_0000.nii.gz, label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\out\\TLIV_008.nii.gz, true label: U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task510_LiverTraumaDGX\\labelsTs\\TLIV_008.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "OUT_FOLDER = \"out\"\n",
    "GIF_FOLDER = \"super_new_post_gifs_fixed\"\n",
    "ORGAN = \"Spleen\"\n",
    "task_name = \"Task511_SpleenTraumaCV\" # \"U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\" Task510_LiverTraumaDGX\n",
    "images = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", #\"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        \"imagesTs\",\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "predicitions = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", # \"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        OUT_FOLDER,\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "true_labels = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", #\"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        \"labelsTs\",\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "\n",
    "data_dicts_test = [\n",
    "    {\"image\": image_name, \"label\": label_name, \"tLabel\": true_name}\n",
    "    for image_name, label_name, true_name in zip(images, predicitions, true_labels)\n",
    "]\n",
    "task_name = \"Task510_LiverTraumaDGX\" # \"U:\\lauraalvarez\\nnunet\\nnUNet_raw_data\\Task511_SpleenTraumaCV\" Task510_LiverTraumaDGX\n",
    "\n",
    "images = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", #\"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        \"imagesTs\",\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "predicitions = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", # \"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        OUT_FOLDER,\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "true_labels = glob.glob(\n",
    "    os.path.join(\n",
    "        \"U:\\\\\", #\"/mnt\", \"chansey\",# \"U:\\\\\",\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        \"labelsTs\",\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "\n",
    "data_dicts_test_2 = [\n",
    "    {\"image\": image_name, \"label\": label_name, \"tLabel\": true_name}\n",
    "    for image_name, label_name, true_name in zip(images, predicitions, true_labels)\n",
    "]\n",
    "\n",
    "data_dicts_test = data_dicts_test + data_dicts_test_2\n",
    "\n",
    "csv_list = []\n",
    "for data in data_dicts_test[6:]:\n",
    "    print(f\"Infering for image:{data['image']}, label: {data['label']}, true label: {data['tLabel']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'monai.transforms.utility.array.AsChannelFirst'>: Class `AsChannelFirst` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n"
     ]
    }
   ],
   "source": [
    "from SimpleITK import GetArrayFromImage, ReadImage\n",
    "from monai.transforms import EnsureType, EnsureTyped, KeepLargestConnectedComponentd, RemoveSmallObjectsd\n",
    "\n",
    "HOME = \"U:\\\\\"\n",
    "val_transforms_synthetic_spleen = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\", \"tLabel\"]),\n",
    "                AsChannelFirstd(keys=[\"image\", \"label\", \"tLabel\"]),\n",
    "                AddChanneld(keys=[\"label\", \"image\", \"tLabel\"]),\n",
    "                CropForegroundd(keys=[\"image\", \"label\", 'tLabel'], source_key=\"image\"),\n",
    "                Orientationd(keys=[\"image\", \"label\", 'tLabel'], axcodes=\"RAS\"),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"],\n",
    "                    a_min=-150,\n",
    "                    a_max=250,\n",
    "                    b_min=0.0,\n",
    "                    b_max=1.0,\n",
    "                    clip=True,\n",
    "                    \n",
    "                ),\n",
    "                # RemoveSmallObjectsd(keys=[\"label\"], min_size=5000, connectivity=None, independent_channels=True),\n",
    "                KeepLargestConnectedComponentd(keys=[\"label\"], applied_labels=[1,2], is_onehot=False, independent=False, connectivity=None),\n",
    "                # DilationLabel(keys=[\"label\"]),\n",
    "                EnsureTyped(keys=[\"label\", \"image\", \"tLabel\"], data_type='tensor')\n",
    "                # ActiveContour(keys=[\"label\", \"image\"]),\n",
    "                # FillHolesd(keys=[\"label\"]),\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "\n",
    "case_number = \"6:\"\n",
    "# print(\"Loading case: \", data_dicts_test[6:][\"image\"])\n",
    "injures = val_transforms_synthetic_spleen(data_dicts_test[14:])\n",
    "# print(injures[0][\"image\"].shape, injures[0][\"label\"].shape, injures[0][\"tLabel\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import  skimage.measure as measure\n",
    "\n",
    "def get_connected_components(init_label, selected_label, min_size=4000):\n",
    "    result = {}\n",
    "    removed = {}\n",
    "    init_label_ = init_label.copy()\n",
    "    foreground = np.where((init_label_ != selected_label), 0, init_label_)\n",
    "    labelling, label_count = measure.label(foreground == selected_label, return_num=True)\n",
    "    init_clusters = np.unique(labelling, return_counts=True)\n",
    "    for n in range(1, label_count+1):\n",
    "        cluster_size = ndimage.sum(labelling ==n)\n",
    "        if cluster_size < min_size:\n",
    "            labelling[labelling == n] = 0\n",
    "            removed[n] = cluster_size\n",
    "        else:\n",
    "            result[n] = cluster_size\n",
    "    for n in range(1, label_count+1):\n",
    "        if n in result.keys():\n",
    "            labelling[labelling == n] = 2\n",
    "    \n",
    "    return labelling, init_clusters, result, removed\n",
    "\n",
    "# d = dict(injures[i])\n",
    "# labelling, init_clusters, result, removed = get_connected_components(init_label=d[\"label\"].numpy().astype(np.int8), selected_label=2, min_size=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(old_true_mask_injury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(410, 246, 193) (410, 246, 193)\n",
      "TLIV_000_0000.nii.gz 1214314.0\n",
      "{1: 1214314} {2: 1704, 3: 2}\n",
      "(276, 326, 289) (276, 326, 289)\n",
      "TLIV_001_0000.nii.gz 790235.0\n",
      "{1: 790235} {}\n",
      "(396, 238, 216) (396, 238, 216)\n",
      "TLIV_002_0000.nii.gz 8899.0\n",
      "{5: 8899} {1: 3881, 2: 785, 3: 89, 4: 3738, 6: 637, 7: 2, 8: 6664}\n",
      "(336, 285, 246) (336, 285, 246)\n",
      "TLIV_003_0000.nii.gz 351082.0\n",
      "{1: 351082} {2: 61}\n",
      "(381, 295, 184) (381, 295, 184)\n",
      "TLIV_004_0000.nii.gz 40466.0\n",
      "{1: 40466} {2: 13}\n",
      "(359, 244, 206) (359, 244, 206)\n",
      "TLIV_006_0000.nii.gz 39738.0\n",
      "{6: 39738} {1: 4, 2: 2, 3: 40, 4: 21, 5: 2, 7: 6723, 8: 181, 9: 4707}\n",
      "(453, 128, 402) (453, 128, 402)\n",
      "TLIV_007_0000.nii.gz 122192.0\n",
      "{2: 97816, 5: 10051, 10: 14325} {1: 4676, 3: 492, 4: 6024, 6: 4096, 7: 1, 8: 1136, 9: 3524, 11: 2, 12: 2453, 13: 2, 14: 647, 15: 7, 16: 1, 17: 2, 18: 11, 19: 1, 20: 87, 21: 2695, 22: 128}\n",
      "(319, 277, 252) (319, 277, 252)\n",
      "TLIV_008_0000.nii.gz 723755.0\n",
      "{3: 723755} {1: 776, 2: 249, 4: 1922}\n"
     ]
    }
   ],
   "source": [
    "settings = {\"iterations\": 2, \"smoothing\": 2, \"balloon\": 0, \"threshold\": 'auto', 'sigma':2, 'alpha': 7000} #spleen sigma 3\n",
    "\n",
    "def store_evolution_in(lst):\n",
    "    def _store(x):\n",
    "        lst.append(np.copy(x))\n",
    "    return _store\n",
    "\n",
    "names = [os.path.basename(i[\"image\"]) for i in data_dicts_test[14:] if os.path.basename(i[\"image\"])]\n",
    "\n",
    "dice_init = []\n",
    "dice_final = []\n",
    "dice_evolution = []\n",
    "gimages = []\n",
    "scanners = []\n",
    "evolutions = []\n",
    "blended_old_masks = []\n",
    "blended_true_masks = []\n",
    "blended_finals = []\n",
    "\n",
    "for i in range(len(injures)): #len(injures)\n",
    "    # i = 2\n",
    "    if i == 5:\n",
    "        continue\n",
    "    d = dict(injures[i])\n",
    "    original_label = d[\"label\"].squeeze() #antes img\n",
    "    old_old_mask_organ = np.where((original_label != 1), 0, original_label)\n",
    "    cropped_injury = CropForegroundd(keys=[\"image\", \"label\", \"tLabel\"],  source_key=\"label\",  margin=5)(d)\n",
    "    init_label = cropped_injury[\"label\"].squeeze() #antes img\n",
    "    old_old_mask_injury = np.where((init_label != 2), 0, init_label) # save only the injury\n",
    "    old_mask_injury, init_clusters, result, removed = get_connected_components(init_label=old_old_mask_injury.astype(np.int8), selected_label=2, min_size=7000) #liver 7000\n",
    "    print(old_old_mask_injury.shape, old_mask_injury.shape)\n",
    "    init_label_true = cropped_injury[\"tLabel\"].squeeze() #antes img\n",
    "    old_true_mask_injury = np.where((init_label_true != 2), 0, init_label_true) \n",
    "    scanner = cropped_injury[\"image\"].squeeze()\n",
    "    scanners.append(scanner)\n",
    "    old_mask_organ = np.where((init_label != 1), 0, init_label)\n",
    "    gimage = inverse_gaussian_gradient(scanner, sigma=settings['sigma'], alpha=settings['alpha']) #init sigma 3 a=100\n",
    "    gimages.append(gimage)\n",
    "\n",
    "    evolution = [] \n",
    "    callback = store_evolution_in(evolution)\n",
    "    ls = old_mask_injury\n",
    "    injury_size = np.sum(old_mask_injury)/2\n",
    "    print(names[i], injury_size)\n",
    "    print(result, removed)\n",
    "    size = 0\n",
    "    footprint = None\n",
    "    if injury_size < 25000: #spleen 5000\n",
    "        dilation_bool= True\n",
    "        footprint = cube(2) #spleen 8\n",
    "        size = 2 # 3 spleen\n",
    "    else: \n",
    "        dilation_bool= True\n",
    "        footprint = ball(1) # 1 para spleen \n",
    "        size = 1\n",
    "    if size != 0: ls = expand_labels(ls, size) #footprint=cube(2)) expand_labels(ls, 2)\n",
    "    ls = closing(ls)\n",
    "    ls = morphological_geodesic_active_contour(gimage, num_iter=settings['iterations'],  init_level_set=ls, smoothing=settings['smoothing'], balloon=settings['balloon'],  threshold=settings['threshold'], iter_callback=callback) #morphological_chan_vese\n",
    "    if dilation_bool: ls = dilation(ls, footprint) \n",
    "\n",
    "    evolution = [np.where((item != 1), 0, 2) for item in evolution]\n",
    "    blended_evolution =  [torch.tensor(blend_images(np.expand_dims(scanner,0), np.expand_dims(item,0), 0.5)).permute(2,1,3,0) for item in evolution]\n",
    "    evolutions.append(blended_evolution)\n",
    "    blended_old_mask = torch.tensor(blend_images(np.expand_dims(scanner,0), np.expand_dims(old_old_mask_injury,0), 0.5)).permute(2,1,3,0)\n",
    "    blended_old_masks.append(blended_old_mask)\n",
    "    blended_old__true_mask = torch.tensor(blend_images(np.expand_dims(scanner,0), np.expand_dims(old_true_mask_injury,0), 0.5)).permute(2,1,3,0)\n",
    "    blended_true_masks.append(blended_old__true_mask)\n",
    "    ls = np.where((ls != 1), 0, 2) \n",
    "    blended_final = torch.tensor(blend_images(np.expand_dims(scanner,0), np.expand_dims(ls,0), 0.5)).permute(2,1,3,0)\n",
    "    blended_finals.append(blended_final)\n",
    "\n",
    "    from monai.data import MetaTensor\n",
    "    cropped_injury[\"label\"] = MetaTensor(torch.tensor(np.expand_dims(ls,0)), meta=cropped_injury[\"label\"].meta, applied_operations = cropped_injury[\"label\"].applied_operations )\n",
    "    inv_cropped = CropForegroundd(keys=[\"image\", \"label\"], source_key=\"label\",  margin=30).inverse(cropped_injury)\n",
    "    final_mask_injury = torch.where(((inv_cropped[\"label\"][0]) == 1), 2, 0)\n",
    "    final_mask = old_old_mask_organ + final_mask_injury\n",
    "    final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "    d[\"label\"] =  np.expand_dims(final_mask,0)\n",
    "\n",
    "    from sklearn.metrics import jaccard_score\n",
    "    init_dice = np.round(np.sum(old_old_mask_injury[old_true_mask_injury==2])*2.0 / (np.sum(old_old_mask_injury) + np.sum(old_true_mask_injury)),2)\n",
    "    jaccard = jaccard_score(old_old_mask_injury, old_true_mask_injury)\n",
    "    dice_init.append(init_dice)\n",
    "    dice_scores_evol = [np.round(np.sum(seg[old_true_mask_injury==2])*2.0 / (np.sum(seg) + np.sum(old_true_mask_injury)),2) for seg in evolution]\n",
    "    dice_evolution.append(dice_scores_evol)\n",
    "    final_dice = np.round(np.sum(ls[old_true_mask_injury==2])*2.0 / (np.sum(ls) + np.sum(old_true_mask_injury)),2)\n",
    "    dice_final.append(final_dice)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mu:\\lauraalvarez\\traumaAI\\Liver_Segmentation\\visualization_gc_spleen_pres.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m post_pro[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m post_plotting(post_pro[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inj \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(post_pro)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m inj \u001b[39m=\u001b[39m Resized(keys\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtLabel\u001b[39;49m\u001b[39m\"\u001b[39;49m], spatial_size\u001b[39m=\u001b[39;49m(\u001b[39m512\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m512\u001b[39;49m))(inj)\n\u001b[0;32m      <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m blended_label_in \u001b[39m=\u001b[39m blend_images(inj[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m], inj[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m0.5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/u%3A/lauraalvarez/traumaAI/Liver_Segmentation/visualization_gc_spleen_pres.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m blended_final \u001b[39m=\u001b[39m blended_label_in\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\spatial\\dictionary.py:624\u001b[0m, in \u001b[0;36mResized.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    622\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(data)\n\u001b[0;32m    623\u001b[0m \u001b[39mfor\u001b[39;00m key, mode, align_corners \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_iterator(d, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malign_corners):\n\u001b[1;32m--> 624\u001b[0m     d[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresizer(d[key], mode\u001b[39m=\u001b[39;49mmode, align_corners\u001b[39m=\u001b[39;49malign_corners)\n\u001b[0;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m d\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\monai\\transforms\\spatial\\array.py:905\u001b[0m, in \u001b[0;36mResize.__call__\u001b[1;34m(self, img, mode, align_corners, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    902\u001b[0m     img_ \u001b[39m=\u001b[39m convert_to_tensor(anti_aliasing_filter(img_), track_meta\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    904\u001b[0m img \u001b[39m=\u001b[39m convert_to_tensor(img, track_meta\u001b[39m=\u001b[39mget_track_meta())\n\u001b[1;32m--> 905\u001b[0m resized \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49minterpolate(\n\u001b[0;32m    906\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mimg_\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m), size\u001b[39m=\u001b[39;49mspatial_size_, mode\u001b[39m=\u001b[39;49m_mode, align_corners\u001b[39m=\u001b[39;49m_align_corners\n\u001b[0;32m    907\u001b[0m )\n\u001b[0;32m    908\u001b[0m out, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m convert_to_dst_type(resized\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), img)\n\u001b[0;32m    909\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_process(out, original_sp_size, spatial_size_, _mode, _align_corners, input_ndim)\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\torch\\nn\\functional.py:3910\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3908\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marea\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   3909\u001b[0m     \u001b[39massert\u001b[39;00m output_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 3910\u001b[0m     \u001b[39mreturn\u001b[39;00m adaptive_avg_pool3d(\u001b[39minput\u001b[39;49m, output_size)\n\u001b[0;32m   3912\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   3913\u001b[0m     \u001b[39massert\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vincent Stirler\\.conda\\envs\\env_trauma\\lib\\site-packages\\torch\\nn\\functional.py:1258\u001b[0m, in \u001b[0;36madaptive_avg_pool3d\u001b[1;34m(input, output_size)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(adaptive_avg_pool3d, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, output_size)\n\u001b[0;32m   1257\u001b[0m _output_size \u001b[39m=\u001b[39m _list_with_default(output_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 1258\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49madaptive_avg_pool3d(\u001b[39minput\u001b[39;49m, _output_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# post_plotting = Compose([DilationLabel(keys=[\"label\"]),])\n",
    "# post_pro = post_plotting(injures)\n",
    "\n",
    "post_pro = d.copy()\n",
    "post_plotting = Compose([AsDiscrete(argmax=False), EnsureType(data_type='tensor')])\n",
    "post_pro[\"label\"] = post_plotting(post_pro[\"label\"])\n",
    "inj = dict(post_pro)\n",
    "inj = Resized(keys=[\"image\", \"label\", \"tLabel\"], spatial_size=(512, 512, 512))(inj)\n",
    "blended_label_in = blend_images(inj[\"image\"], inj[\"label\"], 0.5)\n",
    "blended_final = blended_label_in.permute(1, 2, 0, 3)\n",
    "blended_true_label = blend_images(inj[\"image\"], inj[\"tLabel\"], 0.5).numpy()\n",
    "blended_true_label = torch.from_numpy(blended_true_label).permute(1, 2, 0, 3)\n",
    "\n",
    "volume = torch.hstack(\n",
    "    (\n",
    "        inj[\"image\"].permute(1, 2, 0, 3).repeat(1, 1, 3, 1),\n",
    "        blended_final,\n",
    "        blended_true_label,\n",
    "    )\n",
    ")\n",
    "volume = volume.permute(0, 1, 3, 2)\n",
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLIV_000_0000.nii.gz - init: 0.81 - final: 0.84\n",
      "[0.83, 0.83, 0.83]\n",
      "TLIV_001_0000.nii.gz - init: 0.83 - final: 0.84\n",
      "[0.84, 0.84, 0.84]\n",
      "TLIV_002_0000.nii.gz - init: 0.37 - final: 0.68\n",
      "[0.69, 0.67, 0.64]\n",
      "TLIV_003_0000.nii.gz - init: 0.67 - final: 0.71\n",
      "[0.7, 0.69, 0.68]\n",
      "TLIV_004_0000.nii.gz - init: 0.81 - final: 0.79\n",
      "[0.8, 0.8, 0.79]\n",
      "TLIV_006_0000.nii.gz - init: 0.68 - final: 0.78\n",
      "[0.77, 0.78, 0.78]\n",
      "TLIV_007_0000.nii.gz - init: 0.46 - final: 0.47\n",
      "[0.47, 0.47, 0.47]\n",
      "TLIV_008_0000.nii.gz - init: 0.88 - final: 0.89\n",
      "[0.89, 0.89, 0.89]\n",
      "0.787 0.857\n"
     ]
    }
   ],
   "source": [
    "names = [os.path.basename(i[\"image\"]) for i in data_dicts_test[14:] if os.path.basename(i[\"image\"]) != \"TLIV_005_0000.nii.gz\"]\n",
    "dice_liver_i = []\n",
    "dice_liver_f = []\n",
    "for name, dice_i, dice_e, dice_f in zip(names[:], dice_init, dice_evolution, dice_final):\n",
    "    if name.split(\"_\")[0] != 'TRMSPL':\n",
    "        print(f\"{name} - init: {dice_i} - final: {dice_f}\")\n",
    "        print(dice_e)\n",
    "        dice_liver_i.append(dice_i)\n",
    "        dice_liver_f.append(dice_f)\n",
    "\n",
    "print(np.round(np.sum(dice_liver_i)/7, 3), np.round(np.sum(dice_liver_f)/7,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLIV_000_0000.nii.gz - init: 0.81 - final: 0.82\n",
      "[0.83, 0.83, 0.83, 0.82, 0.82, 0.81]\n",
      "TLIV_001_0000.nii.gz - init: 0.83 - final: 0.83\n",
      "[0.84, 0.84, 0.84, 0.84, 0.83, 0.83]\n",
      "TLIV_002_0000.nii.gz - init: 0.37 - final: 0.42\n",
      "[0.69, 0.66, 0.61, 0.53, 0.43, 0.34]\n",
      "TLIV_003_0000.nii.gz - init: 0.67 - final: 0.67\n",
      "[0.7, 0.69, 0.67, 0.66, 0.64, 0.63]\n",
      "TLIV_004_0000.nii.gz - init: 0.81 - final: 0.73\n",
      "[0.8, 0.8, 0.79, 0.76, 0.73, 0.7]\n",
      "TLIV_006_0000.nii.gz - init: 0.68 - final: 0.78\n",
      "[0.77, 0.79, 0.79, 0.77, 0.76, 0.75]\n",
      "TLIV_007_0000.nii.gz - init: 0.46 - final: 0.44\n",
      "[0.47, 0.47, 0.46, 0.44, 0.42, 0.41]\n",
      "TLIV_008_0000.nii.gz - init: 0.88 - final: 0.87\n",
      "[0.89, 0.89, 0.89, 0.88, 0.87, 0.86]\n",
      "0.787 0.794\n"
     ]
    }
   ],
   "source": [
    "names = [os.path.basename(i[\"image\"]) for i in data_dicts_test[14:] if os.path.basename(i[\"image\"]) != \"TLIV_005_0000.nii.gz\"]\n",
    "dice_liver_i = []\n",
    "dice_liver_f = []\n",
    "for name, dice_i, dice_e, dice_f in zip(names[:], dice_init, dice_evolution, dice_final):\n",
    "    if name.split(\"_\")[0] != 'TRMSPL':\n",
    "        print(f\"{name} - init: {dice_i} - final: {dice_f}\")\n",
    "        print(dice_e)\n",
    "        dice_liver_i.append(dice_i)\n",
    "        dice_liver_f.append(dice_f)\n",
    "\n",
    "print(np.round(np.sum(dice_liver_i)/7, 3), np.round(np.sum(dice_liver_f)/7,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "dice_spleen_i = []\n",
    "dice_spleen_f = []\n",
    "for name, dice_i, dice_e, dice_f in zip(names, dice_init, dice_evolution, dice_final):\n",
    "    if name.split(\"_\")[0] == 'TRMSPL':\n",
    "        print(f\"{name} - init: {dice_i} - final: {dice_f}\")\n",
    "        print(dice_e)\n",
    "        dice_spleen_i.append(dice_i)\n",
    "        dice_spleen_f.append(dice_f)\n",
    "\n",
    "print(np.round(np.sum(dice_spleen_i)/7, 3), np.round(np.sum(dice_spleen_f)/7,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gimages\n",
    "scanners\n",
    "evolutions = []\n",
    "blended_old_masks = []\n",
    "blended_true_masks = []\n",
    "blended_finals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521a8ede6a904a8aa783d9dacf78ac90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=179, description='slice', max=358), IntSlider(value=5, description='i', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice=<class 'slice'>, i=5)>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b, c, d, e = 0, 1, 2, 2, 2\n",
    "a = 0\n",
    "b = 2\n",
    "i = 5\n",
    "def dicom_animation(slice= slice, i=i):\n",
    "    f, axarr = plt.subplots(1, 7, figsize=(30, 20))\n",
    "    axarr[0].imshow(gimages[i][slice, :, :], cmap=\"bone\")\n",
    "    axarr[1].imshow(scanners[i][slice, :, :], cmap=\"bone\")\n",
    "    axarr[2].imshow(blended_true_masks[i][:, slice, :,:])\n",
    "    axarr[3].imshow(blended_old_masks[i][:, slice, :,:])\n",
    "    axarr[4].imshow(evolutions[i][a][:, slice, :,:])\n",
    "    axarr[5].imshow(evolutions[i][b][:, slice, :,:])\n",
    "    # axarr[6].imshow(blended_evolution[c][:, slice, :,:])\n",
    "    # axarr[7].imshow(blended_evolution[d][:, slice, :,:])\n",
    "    axarr[6].imshow(blended_finals[i][:, slice, :,:])\n",
    "    axarr[0].set_title(\"Gaussian Gradient\")\n",
    "    axarr[1].set_title(\"Scanner\")\n",
    "    axarr[2].set_title(\"Ground Truth\")\n",
    "    axarr[3].set_title(f\"Init {dice_init[i]}\")\n",
    "    axarr[4].set_title(\"Remove small components {}\".format( dice_evolution[i][a]))\n",
    "    axarr[5].set_title(\"Active contours {}, {}\".format(b, dice_evolution[i][b]))\n",
    "    # axarr[6].set_title(\"Evolution {}, {}\".format(c, dice_scores_evol[c]))\n",
    "    # axarr[7].set_title(\"Evolution {}, {}\".format(d, dice_scores_evol[d]))\n",
    "    axarr[6].set_title(\"Expand labels {}\".format(dice_final[i]))\n",
    "    for i in range(7):\n",
    "        axarr[i].set_axis_off()\n",
    "        axarr[i].invert_xaxis()\n",
    "    # print(os.path.basename(data_dicts_test[case_number][\"image\"]))\n",
    "    # print(\"{settings}\".format(settings=settings))\n",
    "interact(dicom_animation, slice=(0,scanners[i].shape[0] - 1), i=(0, len(scanners)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22cf691aee0>]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABPOUlEQVR4nO2dd3gc1bn/P+9qtasuWc0dF2wDxqbZgIFQAgEMKaQQLvxIIISEm4SUe5PcBG4KuUlIIAUIKQQSHCAhlBACTmih2JhmY4MbNi5yldwkq/e27++POTNaCVmSLXkl2e/nefbR7JkzM2dH0nz3Lec9oqoYhmEYRiIJDfYADMMwjMMPEx/DMAwj4Zj4GIZhGAnHxMcwDMNIOCY+hmEYRsIx8TEMwzASjomPYSQQEblPRH58EM9fJyKTD9b5DWOgMPExhhUicrmILBGRehEpddtfEhEZ7LEdbERERWRKl7YfiMhf/PeqmqGqm3s5zzkiUnKwxmkYfcHExxg2iMg3gF8BPwdGASOBLwBnAJF9HJOUsAEagN1zo2+Y+BjDAhHJBn4IfElVH1PVWvVYrqpXqmqz63efiNwlIk+LSD3wfhH5oIgsF5EaESkWkR/EnfcpEflKl2utEpGPicftzsKqEZHVIjLD9UkVkV+KyDYRqRaRV0Uk1e37m4jsdu2LROTYHj7Xh0RkhYhUicjrInJcP+9TYB2JyMUislZEakVkh4h8U0TSgWeAMc5FVyciY0QkKiJ3iMhO97pDRKJx5/2WiOxy+z7X5Tr7e88nuuOvcfsqReQLInKyu/dVIvKb/twHYxigqvay15B/AXOBNiDcS7/7gGo8aygEpADnADPd++OAPcBHXf/LgCVxxx8PlONZUhcCbwE5gADHAKNdv98CC4GxQBJwOhB1+z4LZAJR4A5gRZfx/dhtnwiUAqe6c1wNbPXP081nU2BKl7YfAH/prg+wCzjTbY8ATnLb5wAlXc7zQ2AxUAgUAK8DP4q797uBY4E04C9drrO/93yiO/73ru8FQBPwhLv+WHdfzh7svzt7HbyXWT7GcCEf2KuqbX6DsxSqRKRRRM6K6/ukqr6mqjFVbVLVhaq62r1fBTwEnO36zgemichU9/7TwCOq2gK04onI0YCo6ruquktEQngC8zVV3aGq7ar6ujrrS1XnqWeZNeOJw/HOcuvKdcDdqrrEneN+oBmY08N9eNt95ioRqQJu6KFvKzBdRLJUtVJV3+6h75XAD1W1VFXLgP9z9wI8gf6Tqq5R1Qb3mbqyP/fc50eu77+BeuAhd/0dwCt44mwcopj4GMOFciBfRMJ+g6qerqo5bl/833Jx/IEicqqILBCRMhGpxosT5btzNAGPAJ9yonIF8Ge37yXgN3hWTqmI3CMiWe7YFGBT10GKSJKI3CIim0SkBs+Swb9eFyYA3+giJuOBMT3ch5NUNcd/Abf00PcTwMXANhF5WURO66HvGGBb3PttceMYQ+d72un+dtfW0z2PY0/cdmM37zN6GK8xzDHxMYYLb+BZBZf0oW/XUu1/xbNwxqtqNp67Jz477n68b/7nAQ2q+kZwItU7VXUWMB2YBvwPsBfPTXRkN9f+f26MHwCy8VxMdLmeTzFwc7yYqGqaqj7Uh8/YK6q6VFUvwXNlPQE86u/qpvtOPDH0OcK1gee+Gxe3b3x3l+vyvrd7bhzmmPgYwwJVrcJzBf1ORC4VkUwRCYnICUB6L4dnAhWq2iQip+AJRPy53wBiwC9xVg+AC4CfKiLJeG6hJiCmqjFgHnCbC9YnichpLkCfiSeS5XjxkZ/0MK4/AF9w1xARSXeB+sw+3pZ9IiIREblSRLJVtRWocZ8RPAsjr4sr8CHguyJSICL5wPfxYjvgidY1InKMiKQB3+vDEHq854Zh4mMMG1T1Z8DXgW/hPUD3AHcD38YLkO+LLwE/FJFavIfqo930eQAvQP6XuLYsPIGoxHNDleOleQN8E1gNLAUqgFvx/p8ecH13AGvxgvj7+jzLgM/jufYqgSLgMz18jv3l08BW5/77Ap51h6quwxObzc7dNwb4MbAMWOU+19uuDVV9BrgTWODG6H+m5h6u3Zd7bhzGiKotJmcYInIVcJ2qvm+wxzLUEZFjgHfwsvLaeutvGN1hlo9x2ONcSV8C7hnssQxVxJv3FBWREXhW3j9NeIz+YOJjHNaIyIVAGZ4L76+DPJyhzH/izb3ZBLQDXxzc4RjDHXO7GYZhGAnHLB/DMAwj4YR773J4kJ+frxMnThzsYRiGYQwr3nrrrb2qWrC/x5n4OCZOnMiyZcsGexiGYRjDChHZ1nuv92JuN8MwDCPhmPgYhmEYCcfExzAMw0g4Jj6GYRhGwjHxMQzDMBKOiY9hGIaRcA6a+IjIPBEpFZF3urR/RUTWicgaEflZXPuNIlIkIutdyRO/fa5rKxKRG+LaJ4nIEtf+iIhEXHvUvS9y+ycerM9oGIZhHBgH0/K5D2/t9wAReT/eQlvHq+qxwC9c+3Tgcrw14ufirdmSJCJJeKtIXoS3mNcVri94xQ1vV9UpeOXor3Xt1wKVrv12169XqhpaD/BjGoZhGPvLQRMfVV2Et85JPF8Ebolb677UtV8CPKyqzaq6BW/NkFPcq0hVN6tqC/AwcImICHAu8Jg7/n7go3Hnut9tPwac5/r3SFVjy/5/SMMwDOOASHTMZxpwpnOHvSwiJ7v2sXReA77Ete2rPQ+oiivp7rd3OpfbX+36vwcRuU5ElonIspZmEx/DMIxEkWjxCQO5wBzgf4BH+2KVHCxU9R5Vna2qsyORyGANwzAM47Aj0eJTAjyuHm/irSmfj7fk8Pi4fuNc277ay4EcEQl3aSf+GLc/2/XvEVtYwjAMI3EkWnyeAN4PICLTgAiwF5gPXO4y1SYBU4E3gaXAVJfZFsFLSpiv3iJEC4BL3XmvBp502/Pde9z+l9QWLTIMwxhSHLSq1iLyEHAOkC8iJcBNwDxgnku/bgGudsKwRkQeBdYCbcD1qtruzvNl4DkgCZinqmvcJb4NPCwiPwaWA/e69nuBP4tIEV7Cw+UH6zMahmEYB4atZOrInXCMVmx7d7CHYRiGMawQkbdUdfb+HmcVDgzDMIz9oqy2mQXrSqlpOvD5kSY+hmEYxn6xfHsl19y3lO3lDQd8DhOfAHM/GoZh9IWYe1yG+jFTxsTHYdJjGIbRN/xcgVA/FMTExzAMw9gvfMtHMMun31jSn2EYRt9Q5ysK9aM+jYmPYRiGsV8Elo/FfAzDMIxEEcR8zPIxDMMwEkUsEB+zfPqNhXwMwzD6Rizm/ezPmgQmPoZhGMZ+4X9ZN8tnIDDTxzAMo0/4bjezfAYANfUxDMPoE2oxH8MwDCPRWHkdwzAMI+HELNXaMAzDSDS+5dOP6joHT3xEZJ6IlLpVS7vu+4aIqIjku/ciIneKSJGIrBKRk+L6Xi0iG93r6rj2WSKy2h1zp7iptiKSKyLPu/7Pi8iIvozXIj6GYRh9ZIjHfO4D5nZtFJHxwAXA9rjmi4Cp7nUdcJfrm4u3/PapwCnATXFichfw+bjj/GvdALyoqlOBF9373jH1MQzD6BNDOuajqouAim523Q58i86P+0uAB9RjMZAjIqOBC4HnVbVCVSuB54G5bl+Wqi5WL+3iAeCjcee6323fH9duGIZhDADDLuYjIpcAO1R1ZZddY4HiuPclrq2n9pJu2gFGquout70bGNnDeK4TkWUisqy9vX1/P45hGMZhybAqLCoiacD/At9P1DWdVbRPh5qq3qOqs1V1digpKVHDMgzDGNYMt8KiRwKTgJUishUYB7wtIqOAHcD4uL7jXFtP7eO6aQfY49xyuJ+lA/5JDMMwDmM6KhwMA8tHVVeraqGqTlTViXiuspNUdTcwH7jKZb3NAaqd6+w54AIRGeESDS4AnnP7akRkjstyuwp40l1qPuBnxV0d197b+AbokxqGYRzaaJBwcODnOJip1g8BbwBHiUiJiFzbQ/engc1AEfAH4EsAqloB/AhY6l4/dG24Pn90x2wCnnHttwDni8hG4APuvWEYhjFADES2W3iAxvIeVPWKXvZPjNtW4Pp99JsHzOumfRkwo5v2cuC8/RyuYRiG0UessKhhGIaRcKyw6ABiER/DMIy+MaQnmRqGYRiHJn7CQT+8biY+AWb6GIZh9AmL+Qwgpj2GYRh9Q1URGSbzfAzDMIxDg5j2L94DJj6GYRjGfhJT7dcEUzDxCVBzvBmGYfSJmPbP5QYmPh2Y9hiGYfQJRfuV6QYmPoZhGMZ+ohbzMQzDMBJNLGYxnwHDvG6GYRh9w7LdDMMwjIQTc/N8+oOJj2EYhrFfqCqhfvrdTHzisAXlDMMwekfpX103OLiLyc0TkVIReSeu7ecisk5EVonIP0QkJ27fjSJSJCLrReTCuPa5rq1IRG6Ia58kIktc+yMiEnHtUfe+yO2f2Ncxx0x7DMMwesWbZDp0LZ/7gLld2p4HZqjqccAG4EYAEZkOXA4c6475nYgkiUgS8FvgImA6cIXrC3ArcLuqTgEqAX+l1GuBStd+u+vXJ2Jm+RiGYfTKkJ5kqqqLgIoubf9W1Tb3djEwzm1fAjysqs2qugVvaexT3KtIVTeragvwMHCJeJ/6XOAxd/z9wEfjznW/234MOE/6eJdMewzDMHpHh3l5nc8Cz7jtsUBx3L4S17av9jygKk7I/PZO53L7q13/9yAi14nIMhFZBmb5GIZh9IVYbJimWovId4A24MHBuL6Pqt6jqrNVdbb3fjBHYxiGMTwYiMKi4YEZSt8Rkc8AHwLO0470sh3A+Lhu41wb+2gvB3JEJOysm/j+/rlKRCQMZLv+vWKWj2EYRu8oQzjm0x0iMhf4FvARVW2I2zUfuNxlqk0CpgJvAkuBqS6zLYKXlDDfidYC4FJ3/NXAk3HnutptXwq8pH3MoTbpMQzD6J2BmGR60CwfEXkIOAfIF5ES4Ca87LYo8LxTzcWq+gVVXSMijwJr8dxx16tquzvPl4HngCRgnqqucZf4NvCwiPwYWA7c69rvBf4sIkV4CQ+X93XMZvkYhmH0zkAUFj1o4qOqV3TTfG83bX7/m4Gbu2l/Gni6m/bNeNlwXdubgE/u12D9Y2MHcpRhGMbhhS0mN8DYgnKGYRi9Y4VFBxircGAYhtE7qtrv+jomPnFYzMcwDKN3bDG5Aca0xzAMo3cs5jPAWFVrwzCM3hnqhUWHHRbzMQzD6J0hXVh0OGIxH8MwjN4Z7oVFhxwmPYZhGL2jii2jPZDEzO9mGIbRKxbzGWDM62YYhtE7FvMZYKzCgWEYRu9YqvUAY143wzCM3rFJpgOMZbsZhmH0jlk+A4xpj2EYRu94pd3M8hkwrMKBYRhG7wzEYnImPnFYzMcwDKN3hnTMR0TmiUipiLwT15YrIs+LyEb3c4RrFxG5U0SKRGSViJwUd8zVrv9GEbk6rn2WiKx2x9wpLu9vX9foC5btZhiG0TsxVUL9VI9eDxeRP/elrRvuA+Z2absBeFFVpwIvuvcAFwFT3es64C53nVy85bdPxVu19KY4MbkL+HzccXN7uUavxGwlU8MwjF5J1CTTY+PfiEgSMKu3g1R1EVDRpfkS4H63fT/w0bj2B9RjMZAjIqOBC4HnVbVCVSuB54G5bl+Wqi5WL1DzQJdzdXeNXrFsN8MwjN45qJNMReRGEakFjhORGveqBUqBJw/weiNVdZfb3g2MdNtjgeK4fiWuraf2km7ae7rGexCR60RkmYgsA8t2MwzD6AtKvxcy3bf4qOpPVTUT+LmqZrlXpqrmqeqN/bwuzmI5qI/73q6hqveo6mxVnQ0W8zEMw+gLA1HVOtyHi9woImOBCfH9nVttf9kjIqNVdZdznZW69h3A+Lh+41zbDuCcLu0LXfu4bvr3dI1esWw3wzCM3klIzEdEbgFeA74L/I97ffMArzcf8DPWrqbDfTcfuMplvc0Bqp3r7DngAhEZ4RINLgCec/tqRGSOy3K7qsu5urtGr1jMxzAMo3disf7HfHq1fICPAUepavP+nFhEHsKzWvJFpAQva+0W4FERuRbYBlzmuj8NXAwUAQ3ANQCqWiEiPwKWun4/VFU/ieFLeBl1qcAz7kUP1+gV0x7DMIzeGYjyOn0Rn81AMrBf4qOqV+xj13nd9FXg+n2cZx4wr5v2ZcCMbtrLu7tGX7AKB4ZhGH2jv263vohPA7BCRF4kToBU9av9uvIQxGI+hmEYvTMQ5XX6Ij7z3euQxywfwzCM3okNQHmdvmS73d9bn0MFs3wMwzB6JyGWj4hsoZu5Mqo6uX+XHnqY5WMYhtE7A1FYtC9ut9lx2ynAJ4Hcfl11iGKWj2EYRu8kZDE5VS2Pe+1Q1TuAD/bvskMTq3BgGIbROwmxfOKXN8ATq9l9OW44YpaPYRhG78S8pUz7RV9E5Jdx223AVvZj4uZwwiocGIZh9E5CLB9VfX+/rjCcMO0xDMPolYTEfEQkW0Ru85ceEJFfikh2/y47NDHLxzAMo3cStZjcPKAWz9V2GVAD/KlfVx2iWMzHMAyjdwZiMbm+xHyOVNVPxL3/PxFZ0a+rDlFsno9hGEbveDGf/p2jL5ZPo4i8z38jImcAjf277NDELB/DMIze0QTVdvsicH9cnKcS+Ez/Ljs0McvHMAyjdwYi5tOXbLcVwPEikuXe1/TrikMYs3wMwzB6ZyAKi/Yl2+0nIpKjqjWqWuNWFf1xv646RLEKB4ZhGL0zEIVF+xLzuUhVq/w3qlqJt+roASMi/y0ia0TkHRF5SERSRGSSiCwRkSIReUREIq5v1L0vcvsnxp3nRte+XkQujGuf69qKROSGvo7LLB/DMIzeGYhJpn0RnyQRifpvRCQViPbQv0dEZCzwVWC2qs4AkoDLgVuB21V1Cl5c6Vp3yLVApWu/3fVDRKa7444F5gK/E5EkEUkCfgtcBEwHrnB9e8ViPoZhGL2jiZhkCjwIvCgi14rItcDzQH/X+AkDqSISBtKAXcC5wGNu//3AR932JXHXeww4T7wE80uAh1W1WVW3AEXAKe5VpKqbVbUFeNj17RXTHsMwjN5JyDwfVb1VRFYCH3BNP1LV5w70gqq6Q0R+AWzHS9n+N/AWUKWqba5bCTDWbY8Fit2xbSJSDeS59sVxp44/prhL+6ndjUVErgOuA4iMmmIVDgzDMPpAopbRRlWfBZ7t36U8RGQEniUyCagC/obnNks4qnoPcA9AdPRUtZiPYRhG7yQq5jPQfADYoqplqtoKPA6cAeQ4NxzAOGCH294BjAdw+7OB8vj2Lsfsq71XLOZjGIbROwkpLHoQ2A7MEZE0F7s5D1gLLAAudX2uBp502/Pde9z+l9RTifnA5S4bbhIwFXgTWApMddlzEbykhPl9GZhpj2EYRu8oiVlGe0BR1SUi8hjwNt76QMvxXF9PAQ+7OUTLgXvdIfcCfxaRIqACT0xQ1TUi8iiecLUB16tqO4CIfBl4Di+Tbp6qrunL2CzmYxiG0Tsx1f6uJbdv8RGR1XS/wo0AqqrHHehFVfUm4KYuzZvxMtW69m0CPrmP89wM3NxN+9PA0/s9rv09wDAM4zBDVdGDnO32oX6deRhilo9hGEbP+I/Jg+Z2U9Vt/raITACmquoLbpJpwt11icCy3QzDMHrG/5KeiJVMP483ufNu1zQOeKJ/lx2aWLabYRhGz/hf0kP9VJ++ZLtdj5cKXQOgqhuBwn5ddYhi2mMYhtEzfgHmRBQWbXZlatwFJcwhGpu3mI9hGEbP+I9J6We+W1/E52UR+V+8Wmzn41Uk+Ge/rjpEsZiPYRhGzyQs5gPcAJQBq4H/BJ5W1e/077JDE4v5GIZh9EzsYGe7xXGuqv4B+IPfICJXq2p/K1sPOUx7DMMwesa3fBIR8/m+iNzlyuGMFJF/Ah/u32WHJhbzMQzD6BmNeT8TUVj0bGATsBJ4Ffirql7a8yHDE5MewzCMnvGz3RIR8xmBV/ZmE9AMTJD+1lUYopjlYxiG0TN+zKe/MtAX8VkMPKuqc4GTgTHAa/266hDFtMcwDKNnBirbrS8JBx9Q1e0AqtoIfFVEzurfZYcmMcu1NgzD6JGOhIODlO0mIker6jogX0Tyu+yu69dVhygmPYZhGD1z0AuLAl8HrgN+2d31gXP7deUhiMV8DMMweuagTzJV1evcz/d38+qX8IhIjog8JiLrRORdETlNRHJF5HkR2eh+jnB9RUTuFJEiEVklIifFnedq13+jiFwd1z5LRFa7Y+7sa4KEed0MwzB6ZqAsn75UtU4Rka+LyOMi8ncR+S8RSenXVeFXeEkMRwPHA+/iVVJ4UVWnAi+69wAX4S2RPRXPErvLjSsXb0G6U/Gy8W7yBcv1+XzccXP7NCqzfAzDMHok1lHcrV/0JdvtAeBY4NfAb9z2nw/0giKSDZyFWyZbVVtUtQq4BPCrJtwPfNRtXwI8oB6LgRwRGQ1cCDyvqhWqWgk8D8x1+7JUdbF69XIeiDtXj5jlYxiG0TOJiPn4zFDV6XHvF4jI2n5ccxJerbg/icjxwFvA14CRqrrL9dkNjHTbY4HiuONLXFtP7SXdtL8HEbkOz5oiMmqKxXwMwzB6IZGFRd8WkTn+GxE5FVjWj2uGgZOAu1T1RKCeDhcbAM5iOehKoKr3qOpsVZ0tibigYRjGMGegCov2RXxmAa+LyFYR2Qq8AZzsAvqrDuCaJUCJqi5x7x/DE6M9zmWG+1nq9u8AxscdP8619dQ+rpv2XjHLxzAMo2d0gAqL9sXt1rdgfR9R1d0iUiwiR6nqeuA8YK17XQ3c4n4+6Q6ZD3xZRB7GSy6oVtVdIvIc8JO4JIMLgBtVtUJEapy1tgS4Ci9e1TNi+QaGYRi9kbAlFVR1W7+u0D1fAR4UkQiwGbgGzwp7VESuBbYBl7m+TwMXA0VAg+uLE5kfAUtdvx+qaoXb/hJwH5AKPONePSKIredjGIbRC4m0fAYcVV0BzO5m13nd9FXg+n2cZx4wr5v2ZcCM/R2XZbsZhmH0TCJjPocNFvMxDMPomURmux0WCBbzMQzD6I2BKixq4uMjWMzHMAyjFxJWXudwwmI+hmEYPdMhPv07j4mPQ7CYj2EYRm/EBijbzcQnDpMewzCMnrGYz0HAYj6GYRg9Y6nWB4FYbLBHYBiGMbRRS7UeWEQENcebYRhGj/hPSbN8BhDLdjMMw+iZWMwSDgYcy3YzDMPoGf9LuvRzKVMTH4dVODAMw+gdi/kcBCzbzTAMo2eCbLd+qo+Jj49YzMcwDKM3/MQss3wGCKtwYBiG0TtBzMey3QYOkx7DMIyeCSoc9PM8gyY+IpIkIstF5F/u/SQRWSIiRSLyiFvlFBGJuvdFbv/EuHPc6NrXi8iFce1zXVuRiNzQ1zFZzMc42LTHlN+8tJHL7n6Dvy0rprqxlf96eDnVDa28samcR5cWA/DOjmrqmtsGebSG8V46Eg6Gr+XzNeDduPe3Arer6hSgErjWtV8LVLr2210/RGQ6cDlwLDAX+J0TtCTgt8BFwHTgCte3V6zCgTGQNLe1s7K4CoCfPbuOuxZuYsOeWn7x7w28uaWCBetLWVFcxRMrdrK8uJIHl2zjtuc30NIW4+N3vc6Di7dRXNHAzU+tpbK+ZXA/jGE4/OfksBQfERkHfBD4o3svwLnAY67L/cBH3fYl7j1u/3mu/yXAw6rarKpbgCLgFPcqUtXNqtoCPOz69jwmrMKB0X9a22PMX7mT8rpm5q/Yycd+9xrldc28+G4pC9eXUtvUYc3UNbdT76yberdd39xGXXMbLW0xyutbeGldKX94ZQuX/PY1dlc3DdbHMoyA4V7V+g7gW4Bva+QBVarq/2eWAGPd9ligGMDtr3b9g/Yux+yr/T2IyHUiskxElrW1t1m2m9Evqhtb+cRdr/PVh5bz0Jvb2VvXQkyhsqGVOicqvthkRMOB0ABOeNqpb2mjzglUXdz+7RUNPLdmN29tq+Tbj60yF7ExaAzb8joi8iGgVFXfSvS1u6Kq96jqbFWdHQ6H7R/aOCDa2mPEYsrLG8pYVVINeELkC0288PhiUpgV9d53EZqYQlldM+AJUmdLqY2F60t5ZFkxdc1tPPvOblaVVCXwkxpGXMynn+oxGJbPGcBHRGQrnkvsXOBXQI6IhF2fccAOt70DGA/g9mcD5fHtXY7ZV3uPWIUD40C58I5F/OGVzdQ2tQZt8VZLbZNv+bQHbSMzUzpZQvXNbdS3eNt7apo62prbGJGWTCQpRG1ThxjVNbfxo3+t5Z5Fm1FVnn1nd6frG8bBYtiW11HVG1V1nKpOxEsYeElVrwQWAJe6blcDT7rt+e49bv9L6knvfOBylw03CZgKvAksBaa67LmIu8b8vozN5vkYfeWFtXv4zj9Wo6ps3lvP5rL6QEhGZkWpbeoQn/K6FtpjSl1zhzU0KtsTnzonOHVx7jY/tuMLWEZKmIyUMHXNrZ3cdDWN3vulWyv5wl/eYu4dr7Bud01C74Nx+BE7BMvrfBv4uogU4cV07nXt9wJ5rv3rwA0AqroGeBRYCzwLXK+q7S4u9GXgObxsukdd316xmI/RG35F35fWl/LosmLqW9pRhdrmVuqa2hCBwi5WzW5nyTS1xqhu9KyTwsxoYNkAnVxye2p9y8ezlNIjYRcjag8EqrrRE67apjYq6j033Y6qRv66ZHuC7oRxuDJQk0zDvXc5eKjqQmCh296Ml6nWtU8T8Ml9HH8zcHM37U8DT+/veMzyMXqitKaJM3+2gIeum0NtUxut7Uq5i8/UNrVR29xGRiRMZkqYuqY22t1/aXyW2p6aJlKTk8hKTaa1Xals8MSourGN5raYu05HzKeuqY3MlDAiQm1TG42tnviU1TahCnVNbdQ4QQqJN453dlRzzX1LeeZrZ5KfEU3MzTEOGwaqsOigis9Qor9pg8ahT3FlA81tMYr21FHn4is7qzxhqW3yhCIjxbNSttc30O7+Sf0YDsDummbSo2HSI0nePidMpfF94txuGS1t5KZHEIS65lYaW9oB2BXXx48Djc5OpbaplXd31VBW28y28gbW766loaWd86ePPGj3xTi88L+j9zfbzcQnDrN8jK6oKr9/eTNjclLISk0GoKapNXjg76puBDwRqG9pIyPqxWdqm9qCv6ddcZZPaU0TmSlh0qPev57vYiutbQ76dLjdPEEbn5tGSISy2uYgKcEXqNqm1iDRYHR2SqekhJqmVu59ZQt765o5f/pIFm0oY9aEEcG1DeNAiB0CFQ6GFIJVODDey8+fW8+tz67j4TeL4x7qHfGZXZ1EoI30aJjMaLjTfJ14y2dPTRPp0SQyfPFxLrbdnQTKud1a2qlpaiMz6olVXVxq9s44y6emsY20SBI5acnUNrVR48SotqmN6kZvXKW1TVw1702eXLHz4Nwo47ChI+bTv/OY+ARYhQOjM3vrmvndwk0A7iHuP9Q7LJ+dVY2uzROkTD8zLU6g4q2ayoZW0iMdlk+Li/M0trYHfeJrulXUe266jGi4UwbdbmdxxdSzlDKduy/eDVfb1EqNe1XWtwbnq2lq5c0tFQN5q4zDiOFe4WBIYtluBnjWSUllA+V1Xj21aDgUWBAANY1tgRD5lk9DSzs1ja1kOCulLaZBIkB7lz8sv09fiKnXPzMlTE1TKw1dYj4Au6oayUxJJjMl2ROcxg7Lx0/HrmzwPktNUxsPLt7OZXe/wW9e2nhA98c4vDkUCosOOazCgQHw3Sfe4b8eXhG4r8bnprk4j5+Z1voetxt4rjPf7dYTviXTVzKiYdIj4cBKgs6uvF3VTR0WV3OH262msZWapjZUO2JTNY2t7HUZer/49wZeL9rb53EYBsStZGriMzCIWIUDw6O0pok9tU2BBTF+RGoQPwEorW0K/gH9hzp4MRo/4aAnMlLCpEeT+jye9G7O2dre8ce6p6bJWT5hWtuVMufm213TFFhdJRUd7sGqho5KCNsqGthUVsf8lRYLMvpGR7Zb/85j4hOHZbsdvlQ3tHLb8xtoa/cmglY1tAZiMz43DehIq95R2SE48Q9ywMVekoP3/pfDlOSOf7WMLpZPXnok2B6Rlhz0Cfqn9GxNxdS7rt/HH2dJ3Dj97Zom73NNyPM+U3VjK/e/vpVv/m2lWf5Gn+iI+ZjlM2BYzOfwo63dc2W9tH4Pd764kTU7a4L4ToVbQ2f8CO9B7YtOeQ9r63R1qfmTPHNSI0TD3r9bfMIBQGFWSrA90m0XZnVMDs2IJvUaI8pKCZOZ4glXae17RbK4sgHw3G7VjS2Mzk4hHBKqG1upbGilpS1GY2s7Nz6+imff2d3jtYzDG7WEg4HFKyxq6nM4UV7XzNk/X8g9izbFZYO1BBaPby2MG5Hq3jf0ek4/OcBnlBOTjJSO9vRoEslJISJOjEY6oQmHhBFpnhU0MjMl7pzJndxuuc5Siv/nz0xJDkTP/xK1Oy4u1GH5eO7DnNQI2anJzsprCT77o8tKWLCutNfPaRy+WMznIGDSc/igqtz4+Gp2VDWyfndd8AAurmwI/rm2ldeTHkkKHvb1Le3dnist0hG/8VOefUZleyKSHpfhltHlpy80GXGTT/3jvGOTOp0zsI4yO6yjzC6iB52z7PzYVG2T51LMTk2OEx9PbLdXNNAeUyobWigqreX8217mD4s209puE+CMDg7FwqKDi1jM53BiRXEV/167B/Dmvvg11rbsrQ/6bK9oICs1mey05G7P4QvC6OyUTm0Z3Vg+mXHuuIw4Cwg6LB+vgKjX1tnt1lnQ/OuNinPX+dlu+8JPUKhubKWqsZWctGSyUpOpaWwN0rA3l3mfvaqhlbe3VbGxtI6bn37XipUandBgkqlZPgOCVTg4PGhpi9Ee0yBFelRWChX1LcEDeFt5h2utuLKRrBTPQvDx4zbQIQJjclKDtq4xnw7LpyNuE/yMeD/9mE+8cBVkRAO32nsEzZ0zJy1CarInVpkpyWSldIwzEu7+X7u1XWlpi3mi6iyf6i7CW9nQEsS1wiFhy956Kupb+PPibeaaNszyGXjE3G6HAZff8wa3PrsueLhOKcygvL4lcD1tjbN8WtpigXvKZ2yc0Piik58RJcn9J2ZEw0TDIcLuve8ii5//8x63W9Z7BSozJRyIU7ygiXR20/mi1NXdFz/O7oQoJ837XOV1LdS6OUuby+oArwpDRX0zKckhxo5IpbKhhSdX7OB7T7xDSWUjb22rYLVbsdU4/BiowqImPnHYt7pDnw176li3u5ZKJz5HFqR3snyKuyQVZKWGSU1OCsQk3srxLZ/MuGQCf/mDjJSwW9vHc59lxsV84kUF4txu0TAZcfvSo951o+FQUAXbX7IB/Aw3/7qdkxJ88UmPJAXp2/FWmy+q8fOUfMunurGF8roW8tKjjEiLUFHfEkxMLatr5qb5a/jpM+8CsL28YVD+b4pKa2ltj7FmZzXXP/g2P5i/hor6FkprmoLSQWW1zTS1dh+nMw6cYVteR0TGi8gCEVkrImtE5GuuPVdEnheRje7nCNcuInKniBSJyCoROSnuXFe7/htF5Oq49lkistodc6f00TlpMZ9Dk1c37uXzDyyjocWrjba3tpmK+hYyU8IUZqXQ0NIeFPaMn7wJkJWajIgE1o//UM+IhoO2+Ay3+KSC9Ejndl8c9mX5xJfd8a2dDCdm4aQQqclJnaydjDhrKjMlTHJSKJhP5I8zK7XDHedn7QFBtlv89IJilxHX2q4UVzaQmx4hL92JT63LiKtrYU9NM2W1zRRXNHD2LxawcH0ZG/bUcvfLmwZ8Ke+qhhY27qkF4Oan1vLfj6ygor6FuXe8wj/e3sHTq3fx1Opd3Pf6Vl5aV8rdizZz9bw3UVUu+c2r/OalItbtruGcny8IBNToH8M5260N+IaqTgfmANeLyHS8FUpfVNWpwIvuPcBFeEtkTwWuA+4CT6yAm4BT8Rahu8kXLNfn83HHze1tUFbh4NBj4x7v2/HLG0p5fu0eNu7x3Ep76zzx8R+u8N65O76ryn9wB+IzokN8fGHJiJtYGi8s7+3TfcKBP4b4xAI/QcG3kuLP0eG+67B2/HH6c338cWanJgdjGOfmK/nt8e5E6Jwdt6msntz0CCPSO1s+pbXNlNc1s7euma3l9ajC1vJ67n99Kz99Zh0fuO1lymqbWVlcxVOrdgX3u7uMubrmNlYUVwHw97dKWLy5nJ1VjXzgtpcprmjg9y9v4oQfPs/5ty9ic1kdS7dW8uaWCnZWNdIWU7ZXNFBW2xzcj7LaZnZXN9HY2k5pbTM7q5vYsreeFdur2FrewIY9tdzxwgY++fvXWb698j3jMfrGsLV8VHWXqr7ttmvxlroeC1wC3O+63Q981G1fAjygHouBHBEZDVwIPK+qFapaCTwPzHX7slR1sXr+gAfiztUjZvkcOuyta2bur17hieU7gnIza3fVAJ7QlNc3Bw/XriSFJHCp+Wv4ZLqfvtstPsbipzknJ0ng2sp0JXSyU73z56R6QhdJCgWiMzo71ZvsmRRiRFoyuemRIMutIDPqxYniXGm+JRQfF8qMJgfb/lggzvJJSQ4+QyfLJ62z+HR9kFTUt5DnxLk8TnyKSuuIqRcX8it6l9U2s6emmZB4S0S8ta2SexZt5vtPvkNLW4xzf7GQvyzexrKtFZxy8wsc/b1nWLi+lAfe2Monf/86DS1t3PLsOv74yhZWlVRTVFrHqpLqTpW3tzmhKattDibRltY2UVbbzBF5aaRHkoL9AGt31gRj86uKl9U28/KGMpZureTyexZTWd/COzuq2eAsK2P/GNaLyYnIROBEYAkwUlV3uV27AX/pxbFAcdxhJa6tp/aSbtp7xbRn+FPd2Ep7TNlZ1Uh7TNlaXk+Ze3C+68SnPaZsKavnmNFZnUrb+Nlf2anJ5KRF2FbeEDygswPxiZ80mtyx7Vxmvod3/Ig00qNhCjKj3P/ZUzh54gjaY8qcyXlEw574fPGcI7ny1CMAeOCzpzI6J4W89Aj//u+zmJCXzqWzxgWVtMGzkHLSIh1ut3gXXFzMyRun73YLkxp5r+WTldohSgBjslPZUdUR/wECcW5pi7GtwouFrdtdE+x/d5f30PYe+k1MG5nJut21lNU2saemifL6FnZVN1LT1EZRaR0NLe2BEKworqK0tpnWdu93tbfOO0e8sJTWNjG1MIONpXWU1jRRVtdMS3uMotK64Lp761ooyIx67tS65uB37X/RKKvrEKuy2mZKa5rJdIv9FVc28N0n3iEzJcyDn5vDxj21TCnM6HcK8aFOLDYwVa0HTXxEJAP4O/BfqloT/wtXVRWRgy4FInIdniuPrDGTzfIZ5uypaeITd73O2JxUrjtrMgC7q9/7bRi8xdhOn5IfTCAFmFyQzvLtVZ74uAdzlnuY++KTlx4lJTkUFPIEz/01Mjul06TPn3x8ZvD3dPa0gqD9+PE5wXZKchIpLlV65rjsoH3ayEwAPn7SuE6f75eXHU84KURykpCSHGJKYQZFpXVBvAc8EUpOEgrcWLJSkkl1yQrjcz1BColnIcVbPpPy09lR1cjo7JQgDT0vIxrcHz8bcP3uDiuh8wO+mdMm57FhTy17apqD1VjXuHu+p6aJpJCQ5cbqx438PqqeS89fSG9PjWdNnTkln42ldRSV1gVVvf1zei7AFo4elUldU1sny2fNTi8bL76t1FlNJ0/M5fVN5ZTWNLOzykun31Zez/m3L+IPV822Jcd7oSPm07/zDIr4iEgynvA8qKqPu+Y9IjJaVXc515lf42MHMD7u8HGubQdwTpf2ha59XDf934Oq3gPcAzBy8nSTnmFMLKZ89r6llFQ20twWC75h76lpCrZ9y8fHcyt1CMakfE98slKTyUnrbPFkp3ZYFlkpyWRGw0HB0bE5qXzrwqM6LQLni8pAMiEvPdh+94dzERHGjUjlwmM7HpaZ0WTnanOxoNTkYCyFmSlEkkKkRZMIhTqSKJJCErjkJhekd4hPXEzMJz429q4vAk5IRmankJ8RpbS2KVihdfUOTwQ8t5wwKjuFcCjEnpqmwJW3qqRDKPySQL41NC43jZy0ZN7Z0fG7eyfunFUNHZbPqpLq4Hfgf9Goa24L5m5t2FNLa7syc1w2r28qZ0dVI3vrWmhoaWezy/TbsreO3dXZLN1awXnHFJIWGVTn0JBkoAqLJvzOusyze4F3VfW2uF3zgauBW9zPJ+PavywiD+MlF1Q7gXoO+ElcksEFwI2qWiEiNSIyB8+ddxXw694HZjGf4ciyrRWUVDZy+pQ81uysIS89wt665iAeUVzZEHxr71oeZ0R6hMyUMEkhoT2mHFmQAdDZ8gksoA4X2+fOnMTk/AyOGZ3Fm985j8LMjkmficL/xy/MTAmuD3DShBxnYXSIZ9RlwPnJB77F5lduyHFuRvAE+LWicoB9xsR8/PlBm8rqaIsphZlRRmalsGFPh5XSIRRNhMTL7AuHpJP4+HOG2mIaWFZrd3nW0MisKCMzUwJLBgiEwj/eF594t+HWuMnCvpvOF7Bjx2Qj0jG2hpb2IKNuV3UTv395E/e9vpURack89dUzO6XXG96UlIHwTA6GrJ8BfBpYLSIrXNv/4onOoyJyLbANuMztexq4GCgCGoBrAJzI/AhY6vr9UFX9COWXgPuAVOAZ9+oVq3Aw/Lh70WaWba3gT9ecAsCsCSP499o9wTfu+IoF4LnR/BVGc9MihFwxz711zUzO9yyL7NRkst3D2H+InzWtgJLKRjKjYa4768jgfPEP/qFA/Nh+dfkJnDIpl9eLygkJ5GVEXOp1Z1diTlpyMBeoMDMliInkZnS2fMbmeHEhX6x9mp3QeEIY5dW4Ber838PeumZiqkwbmUk4SVhZUh0UcI0XFl98NrkJr4WZKRRmRVkflxTQ9TtiQWaUurjYWFfa3Fh9sRqbk0JuWiQYGxBk3e2paaKxpZ20SBKVDa0s21bJ5PoWSiobmTtj1D6vcTgR0/7He2AQxEdVX8WrZtMd53XTX4Hr93GuecC8btqXATP2Z1yyzyEZQ43K+ha+P38NP/zIseysaqSyoTX45uqLz6ouM/D9B+akggze3VlDS3ss+FbvW0uTCnzxCQcPY986mDM5jzmT8xL1EQeES07w8mw+fPwYjhmdRX5GlNHZKYGgpkeSSHLi67sZR6RHGJEWobapjbwuls+0kRlBXKi8roXG1nai4VCH+GRFKcxKCd5DR6woprC3roVR2SmERILlKqCzRdriUrJ9gRmZFe0k8P7vMTU5iUY3gTQ/o7P4+PsiSaHgfPF4gpbC+rjkiRXbqwDP8qltamPWhBG8snEvOyobeWb1LhZvLmfujFE0t7WTHAoR6m/AYxijaL/jPWAVDjphbrehSyymPP52CWt31vDG5nL+uXInb7h5IUCQljtrgueFregyb2dqoedSK8iIkJfhPVD9YHpueoSU5BCjsz33Sk5qhA8eN5rvfvAYxmQPLcvmQIiEQ0wfkwXAry4/kZ98fCZAMHnWS7t29yJOiHLTI2RGvQQGgGmjvESI/Iwo+Zle/6NdG3jVHOKTLrr7cjwyK6VTxW6fpLinWXwlhpFZKUH6eSQpxHgXmzpmdMd1CzKjwbpJAEe7fVNHZgRtE/M6Mv0Ks7xxxk+w3eniXLurmyipbOCokZlkpyazs6qRreUNVDZ4NfDOuGUBf33z8C60GtP+x3vAxKcTJj5Dk5a2GFfNe5OvP7qSO17YwHaX9vvurpqgGvWSLRWkRZI4ZnRWcFy8cBw7xssmy0uPBplgvvjkZ0bJS4+SlRLm2vdN4oJjR1KYmcLnzpx8yKXdFmRGO2X4zZmcy6wJuUzKT0fEi/nkpHnzkTJc6viItAgiMK0wMziH/7A/dmxHlp7vIvOZ5NyYY7uUJBoZ18cXhSMLOpIp/N+hiGeVjszsmPvkF2H1f59+u/87DQkc5bIFjxqVGXxD9/uPSEsmGk4KRDKpy1f4XdVNNLXGGDciNXAzbi/3YkxvbC5nb10zK4qrKCqt4xuPrgxiW4cTMR0Yy8dSORxW4WDosWRzOamRJBpb2nm1aC8Z0TBb9tYHD5rXN5UHfbdXNHBkQTrp0XAQ15kxNjv4Rjt9TBZ/f9uLe/gPzlwX1/naeVMorW1GRPjeh6Yn+FMOLr+7clawvfx755OTFvESB7KjgfDmpkdoi2lQBqggzro51llUmdEwqZGkoOhpZkqYI3LT2FxWz3HjsoNkgJFZKZ0sopnjctha3sC4EWnsrWuhor6FmWOzWVFcRX5GlHBSKLhufpxl5Vty0XCITDefCrz0cL//6OwU8jKilNU2M31MFk+t3vWelWLH5KRQVd9KbXMb6ZGkwAU4PjeNMTmprCypCtpeLSoDvHp2z6zexd/fLuGaMybSHlOqGls5a2r+IfdlpTtUByZMYZZPHLaM9uCjqtS4+mD/+4/V/Ohfa4OCl2dPK2BbeUOQRLDSBYl9/Kwk3302030rz0lLDtw1eRlR8jMiJIUkyPqaUpjJ6UfmH9wPNgzwM96+ccE07v7U7KDdE+wOd2V+Rpzl4ywK/2Hu/xyZ1THv6ZjRWUFh1lHZKYEAiHSI18isDmHxf28ju5yzIKMj/nNEbhqZKZ7oiEgwtsLMaKf+BW6c05015YuUP4ZRcW69E47ICT7zuBFpjBuRGswRAq9GIHhfdPyEiK3l9Xz776u4et6bfOZPS4MJmIcysZjFfAYcq2o9eCzZXE51Yyv/XLWLU29+kdKaJraVN7B+dy1b9tYTSQpxxpR8WtpjvO3qcvlZTF2Lfo52VQiOyEsjOzWZwsxoEGfIz4jwkePHct1Zkw/roHFPjM5ODSwLgK+dN40bLz6G0dnePKGJeWnBQ3xSfjqpyUmBKPg/4xMFRrsJuMlJQm5ahNy0CMlJQl56JPidFWR2iNIMX3y6nLMgXlicFeSLYDScRE5asueCy4gG5yzIjBIJh4I0+q6rwBbGxaBOHO/P2vBKEfnVLHz89O3dNU3BRNeNe7wJsHnpEV7eUMaOqkYeenM7izaUHcCdHx4M22y3oYpgy2gnElVl4foykkLC8eNyuOIPi/nSOVOobmylsbWdf67aRVtMqWlqY8mWCibkpTHFJQ00tLSTnCS0titJIWHWhBG8tK40sHj8nwUZUcbkpJKfEWHGmGx+/NEZXDB9FKmRJN431SydvnLKpNxg+6Vvns3o7FR21zQxNieF7NRkJuSlMdHFd/IzIsGaQ52soKwURCQQ/MJM71j/wT8yKxpYOlMKM4iGQ0F8pzArSiQpxNicFN43JZ+zphVwRG4aHz9pXLCYHsC5RxcyfXQWM8dlM7Uwg+PGZbN8eyV765qdhdSx+mtBZoflE3XVIU50lk9ueoT0aJixOR1JCn78x2ejmzu0cH0pbTFl7oxRPLhkOxv21HLzU+9y/PhsZk0Ywa9e3MhXzp0SlGI6FFCG7zyfIYslHBxcVJWYekHez92/jBfXlZKdmszvPzWLmMKqHdU0Of/6P1fuDI5bUVzFBdNHBgFsgNkTcnljczmjslKY6Gb++99U/USDgswoP/nYDKJhb0b/p+ZMSNRHPWTx68ONzUnlP052demuPSUQgXBSiEuOH8M5RxcyMjNKOCRMLkjn3KMLO2UgHjsmi+zUZI4alcnJE0dw6qQ8CjK8DLRIOMQvLzs+yKSLhpP42xdOY3JBOpkpyTzwWW9O1/Xvn9JpbLdddkKw/fzXzwbgW3OPprU9Rmokibs/NYsTXHkjX/RGZ6cEpYlmjM0mkhQKqj34f0+jslKYUuilmY/PTaW4okOEVrqU/otnjubBJdtZsL6UuuY21u2qZcH6Uu5ZtJnpo7Ooa27j72+X8ImTxnHlqUcM69iQKgPiNTDxieNw8NcOBut31zJtZAa/W7iJx94q4ZH/nMOL60qZlJ/Olr31vPDuHsCbcd7m5mWs6BLPmZSfTn6Gl/pb29zG+6bm88bmcsbkpAQ1y/yYzxlT83ll417G56YdlDI3Rme6TrS94/ITg+23v38+WSnJfPW8qZ36/P5TXqJDKCT87QunA57Fc8Gx3kTODx03plP/+Jp4+0MkHAqWx/DPDZ54/vTjM7lg+kiKKxupaWqlICPK+NzUYLKx7xI8Ii8tEKSzpxXwl8VeqvXk/HQ2760nJF6Kf35GlKdX7wa8MkQvvetVCFuzs5pl2ypZVVLN8u1VHDM6k8WbKyiva+H7H55OcUUDY3JS35N5N1Txst0s4WDgsGy3AWNnVSPfe+IdHl1WzJqd1Vx4xyKeXr2bhetL2bK3nieXe1bNVad5lsg/lnul9yrqW6hpagtM+lFZKUFasJcKLMFE0DOd22xMTiqnTspjckF6kKJ70hEjePQLp5nwDAGy9uFuCoVk0GNuV5xyBHkZUU4Yn8NPPjaTUEj449Un850PehmP+RlevGhCblpg8c2aMCJYVfa8YwoBL/khJTmJKYXpnay7p9/xivS/vb2KNTtq+Kib9Lt8exUPvbmdh5duZ2dVI+f+ciF/fXM7/1hewhm3vERTazs3/H0VH/nNq9zxwgYA/vzGVpZvr6SuuY0/vrKZ1vYYb22r4LcLioL40pa99RS7aQhd57kNJDHVAZmSb5aPQxCL+ewnre0xlmyu4H1T83llYxmNLe3MnpjLhXcsorapjfG5qVw1ZyLg+cb9cib3vb6VkMDHTxzHT59ZR0V9S6eyN6dNzuP1TeVMKczwrrGlInC5TcxLZ/WOao4alckZU/I4/cg8po/J4qVvnDMYt8A4xIh37YZCwm2XHc9RIzOD7LYpBZkckZfOzqpGZk3I5Q+vbGGqm1c0tdCzaAozo5TWNtPU6lnxb23zEmTOn17I4s3l/HvNHkrcqrH3v7GV1nbl5fVlqCo7qhp5eUMZjy4rJi0SZlXJRj58/Bhumr+Gc44q5OxpBfz4qXeZlJ/O7S9sCOrVvfD1s/nyX98mNZLELz95PBfcvojfXXkS28ob+Oub23nh62fz2wVFbNlbzxlT8rl01jjW7qzhiLy0YF2qvmKTTA8CFvPZN2t31gSrP9727/W8samcv79VwqfuXcLSrRXc9OQabnh8NS+tK6W2qY1LThhDcUUjjzur5p+rdgb/jDuqGplSmEF2WnJgrVw8c3SQvvmxE71viEcWpAfLC/gWz6WzxnHdWZOJhpN48HNzgriDYRwMPnTcGKaOzOQDx4zkgc+ewsxx2Zw1LZ/zji4MhMqf1OonxJx+ZF6QDXhSXPr2iUeM4ITxOby5tWORvAedC+/NLeUscVU67nxxIzGFL5/rxbR+9YL3fsnmchau91x5T63axZqdNXzCLbvx+NslrNtdy8riKp5YvoO2mPLvtXuYv3InW/bWs2hDGbc9v4GnVu3if/+xml3VjVzy21f59YsbKa5o4KdPv0tre4zl2yt56M3tQdHV7lDt/3IKYJZPJ0x8OvD/YK8+fSJf/uvb/GvVLiLhEE986QzufKmIZdsqA5fKn17bElQa/s1LG8lLj3D9+6fw5IqdvLurhkhSKBCeo0d5C44dNy4HgOPGZrOyuIoTj8jh7e2V1DW1ccaUfELizQ85ZnQWyUmhIH32rGkFnBW3Po5hJIJwUij4u7vxomMAz/L/+Elj+eBxo4GOEk7Tx2RRXt9CWW0z/+/UCby9vcpVdkjhuHHZPLV6F9FwiPRomIr6FlKSQ4HVnxQS1uysIRoOcdVpE/jtS0X8c5Xnpq5vaWfBes/F9sSKHajClXOOYOnWCv702lbAs0rufXULAC+8uyeorXfLM+sA+K/zp/KzZ9dz6zPraG1XXlxXSnNbjPte38qcyXl85x+r2VndRDgkvH7juSxYV8qYnFTOnFpAS1uMSDiEWsxnYBEOz5jPgnWl3PrsOp5bs5uy2mbm/ORF/r1mN7c9v4Gb5q/hX6t28q9VuzhrmvfH950nVgNeOZtXNnr/CH6QNSTeXIizphUwtTAjmEtx2cnet7Pc9Ehg1RznFk/zs4+OHZPNF885kuvPncKYnFSe+uqZfGLWOI4fn8P3Pzx9WGcHGYcmyUkhbrvshMB6P+GIHC6eOYoLjx3FrAkjKMiMcvHMUSSFJEjj9hMnjh+Xw0lHePOKrjy1Iwvz4+7/4+SJuaRFwpwyKRdVmDE2K4iFHjcum5h6VSWOG5vNGVPyaWxtJyctmTRXpSE/IxoIT0Y0zPo9tRRkRrnm9ElEwyGeWOEJWlFpHY+/7S38/LPn1rOzuolr3zeJtpjy0JJivvvEO/zfP9eyoriKGT94jqVbK2htH5hUaxMfn0M04aCqoYWWthiNLe38dcl2Glva+e2CIr704Fus313LNfct5a6Fm/jGoyv502tb2F3TxB0vbOT5tZ6g3Pj31YjALR+fyaisFG+xtZQw7TGlvqWdkyd6/0BH5KYFK3aePa0AEeF9U7ykgM+cPomMaJgTxudw3jEjKcyMBvsuOWEMD3z2FGaMzeZjJ44L/hF9i8cwhgtpkTC/u3IWE/LSuf79U3jhv88mLRLmJx+bwZfO8VxoM8dmEw2HmDM5l5Mm5ADe/8Dk/HSmj87i4pmeFXXakXmdfl48czTTR3sC9M0LjgLg1Ml5hJNCwf/S6Ufmcaqbk/Xf53vZhbnpES6d5X35O2daAamRpOCcs10R3pqmNnLTI56XIhzivz4wlSML0vn1SxtpbVeKSuv47hOraWmL8afXtvDyhrKgYkR/MLdbHMPN7eYt6iSoKrtrmhidncqDS7bx6NJiQiHhritn8eHfvMoxo7M4YXwOd764kRXFlTy5YifNbTG27m0gEg5x79Wz+fS9b/K7hZuIJIWC5ZEnF6SzuayeUyflMiYnlYtmjuJPr23lyjkT+OfKnV5W24em85HfvMY5RxVw8sRclm2rDNwTn33fJAqzUjiyIJ27PnVSMF/ize98IPgM8e4MwzhUSE4KkZ3mfXmKj0umR8M89dX3MTYnjZa2GHnpEWaOzeaOy08gHApxZGE6nz9zEp90gnHB9FH89c3tXHjsKPLTo6wsqeKMKfmce3Qhl5/sLfB8xpQ8MlPCzJ0xmpa2GGt21vCxE8fy6LISZozJ4uyjCrjv9a2ce7SXnXf2tAIWri/jc2dOYrdb6feGi47mW4+t4uxpBWSmJHPxzNH8+qWiINninR01pCSHAi/Hp07r/5w5sZIyHuOnzdDIpT9j008uHuyhdCIWUxpb20mPhlm2tYIF60sZPyKNs48q4JO/f4MrT53A3rpm5r22hf+58Ch+8dx6po3MZP2eWkZmpgTLEvtl8f2qALnpEcpqm/nESeP45WXHc+UfF/NaUTn/95FjufXZdYxIi3DrJ47jU/cu4acfn8kVpxzBOzuq+Y+73+CxL57O8u1VbNhTyw8+ciz/XLmTUyblMjIrhbb2GGGzWAwjobS2xwiHpJN7urU9RkiEkHhFeE+bnEcoJNQ2tfLXJdu55oxJzF+5k/K6Zj592gQ+fe+bfP38aZwxJZ/1u2u56FeL+Pmlx/P06l28uK6UX11+Al97eAVH5Kax8JvnBKnyIvKWqs7e19j2xSErPiIyF/gVkAT8UVVv6an/+GkzNPyJW9ny0w8e9LE1tbaTkpzE9vIGFm8uB/EyvP62rIT0aBLjRqTy7b+v5gtnH8m/Vu3krW2VXHPGJH790kbAcw+Ozk5hV3VTUI3bXzgrPyPKi984m1/+ez0PvLGND84czYY9tWwsreO+a07m+gffZu6M0Zw6KZcbHl/Fk9e/j5njvKD/71/exO3/cQIvvLuH9GiY9x9VyNKtFZx0xIhhMwHOMIyBYadbOLCotI7lxVVcNns8331iNacfmR+4B8HEpxMikgRsAM4HSvCW2r5CVdfu65jx02Zo0sdvZctPL6ayoZVIOERI4N1dtRw9KpOSykY27KklKSScOimX9btraW6LMSk/nVeL9nLUqEw2l9WxbnctZxyZz9Ord7F+Ty3ZqcmcP30kf3+7hCNy00hOCvGvVbu4YPpIFqwvDbLA/LkB4AlJu2qwVLG/b9aEEcz7zMn87+OreWr1Lr7/oek8srSYlvYYv77iRL760HL+58KjuGjmaGqbWrn75c1cddoE6lvaWb+7hrkzRrOrupERaRGi4RCltc1BoUXDMIwDwcQnDhE5DfiBql7o3t8IoKo/3dcxE46aqfKxW8hJS6aqoRURSA551sT+rPXjL/ObEfUyVdbtqmFndROT8tPZU9NES1uM9x9dyIJ1pZw6OZf/+8ixrNtdy4//9S7/cfJ42mPKq0V7ue2y47ln0WaOGZ3FB48bzSNLi7ny1CPISYs4v241J4zPobktRntMSd/PiWKGYRgDgYlPHCJyKTBXVT/n3n8aOFVVv9yl33XAdQDjj5gw6+aHF7KqpJojCzNoam2noaWd48flsG53DaOyUzh5Yi51zW28unEvUwozSIsksbnMmzG8fk8tI9KSOX58Dos3lXPKpFxy0iI0t7WzZmcNM8dmU9/cRktbjMKsFGqaWsl0K0UahmEMV0x84uir+MQze/ZsXbZsWaKGaBiGcUhwoOJzqKYl7QDGx70f59oMwzCMIcChKj5LgakiMklEIsDlwPxBHpNhGIbhOCSj1KraJiJfBp7DS7Wep6prBnlYhmEYhuOQFB8AVX0aeHqwx2EYhmG8l0PV7WYYhmEMYUx8DMMwjIRj4mMYhmEkHBMfwzAMI+EckpNMDwQRqQXWD/Y4hgj5wN7BHsQQwe5FB3YvOrB70cFRqpq5vwcdstluB8D6A5mleygiIsvsXnjYvejA7kUHdi86EJEDKg1jbjfDMAwj4Zj4GIZhGAnHxKeDewZ7AEMIuxcd2L3owO5FB3YvOjige2EJB4ZhGEbCMcvHMAzDSDgmPoZhGEbCOezER0Tmish6ESkSkRu62R8VkUfc/iUiMnEQhpkQ+nAvvi4ia0VklYi8KCITBmOciaC3exHX7xMioiJyyKbZ9uVeiMhl7m9jjYj8NdFjTBR9+B85QkQWiMhy939y8WCM82AjIvNEpFRE3tnHfhGRO919WiUiJ/V6UlU9bF54yytsAiYDEWAlML1Lny8Bv3fblwOPDPa4B/FevB9Ic9tfPJzvheuXCSwCFgOzB3vcg/h3MRVYDoxw7wsHe9yDeC/uAb7otqcDWwd73AfpXpwFnAS8s4/9FwPPAALMAZb0ds7DzfI5BShS1c2q2gI8DFzSpc8lwP1u+zHgPBGRBI4xUfR6L1R1gao2uLeL8VaEPRTpy98FwI+AW4GmRA4uwfTlXnwe+K2qVgKoammCx5go+nIvFMhy29nAzgSOL2Go6iKgooculwAPqMdiIEdERvd0zsNNfMYCxXHvS1xbt31UtQ2oBvISMrrE0pd7Ec+1eN9sDkV6vRfOjTBeVZ9K5MAGgb78XUwDponIayKyWETmJmx0iaUv9+IHwKdEpARv/bCvJGZoQ479fZ5YeR2jd0TkU8Bs4OzBHstgICIh4DbgM4M8lKFCGM/1dg6eNbxIRGaqatVgDmqQuAK4T1V/KSKnAX8WkRmqGhvsgQ11DjfLZwcwPu79ONfWbR8RCeOZ0uUJGV1i6cu9QEQ+AHwH+IiqNidobImmt3uRCcwAForIVjyf9vxDNOmgL38XJcB8VW1V1S3ABjwxOtToy724FngUQFXfAFLwio4ebvTpeRLP4SY+S4GpIjJJRCJ4CQXzu/SZD1ztti8FXlIXUTvE6PVeiMiJwN14wnOo+vWhl3uhqtWqmq+qE1V1Il786yOqekAFFYc4ffkfeQLP6kFE8vHccJsTOMZE0Zd7sR04D0BEjsETn7KEjnJoMB+4ymW9zQGqVXVXTwccVm43VW0TkS8Dz+FlssxT1TUi8kNgmarOB+7FM52L8AJslw/eiA8efbwXPwcygL+5nIvtqvqRQRv0QaKP9+KwoI/34jngAhFZC7QD/6Oqh5x3oI/34hvAH0Tkv/GSDz5zKH5ZFZGH8L5w5Lv41k1AMoCq/h4v3nUxUAQ0ANf0es5D8D4ZhmEYQ5zDze1mGIZhDAFMfAzDMIyEY+JjGIZhJBwTH8MwDCPhmPgYhmEYCcfExzCGASJyn4hcehDP/wMR+ebBOr9hdMXExzD2A1f1wjCMfmLiYxgOEfmeW7vlVRF5yLcERGShiNwhIsuAr4nIh91aT8tF5AURGSkiIRHZKCIF7piQW9ukQEQ+KSLviMhKEVnk9ieJyC9c+yoR+Ypr/76ILHXt93RXUV1EZonIyyLylog817V6sIhki8g2V5MOEUkXkWIRSRaRz7vzrxSRv4tIWjfnX+iXDhKRfFdSyB/zz93xq0TkPwfy/huHFyY+hgGIyMnAJ4DjgYvwCqnGE1HV2ar6S+BVYI6qnohXZv9brpDkX4ArXf8PACtVtQz4PnChqh4P+BUirgMmAieo6nHAg679N6p6sqrOAFKBD3UZZzLwa+BSVZ0FzANuju+jqtXACjoKwX4IeE5VW4HH3fmPB97Fq03WV67FK5tyMnAy8HkRmbQfxxtGgLkQDMPjDOBJVW0CmkTkn132PxK3PQ54xFkcEWCLa58HPAncAXwW+JNrfw24T0QeBR53bR/AW7SwDUBV/bVS3i8i3wLSgFxgDRA/lqPwipw+74yiJKC7GlqPAP8BLMArEfU71z5DRH4M5OCVTnpun3fkvVwAHBcXe8rGKyi6Zd+HGEb3mPgYRt+oj9v+NXCbqs4XkXPw1nRBVYtFZI+InIu3ENmVrv0LInIq8EHgLRGZ1d0FRCQFTyRmu3P9AK9QZaduwBpVPa2X8c4HfiIiucAs4CXXfh/wUVVdKSKfwRUI7UIbHV6R+OsL8BVV3R/BMoxuMbebYXi8BnxYRFJEJIMu7q4uZNNRLv7qLvv+iOd++5uqtgOIyJGqukRVv49X8Xg88Dzwn34CgxMJ/0G/142hu+y29UCBeGvH4OI4x3btpKp1eFWZfwX8yx8L3vIQu5z77squxzm24gkWXcbwHPBFdywiMk1E0vdxDsPoERMfwwBUdSmetbAKb8XW1Xir2HbHD/Aqfb8F7O2ybz6eO+tPcW0/F5HVIvIO8DqwEk+ktgOrRGQl8P/cYmx/AN7Be9Av7WacLXiCcKs7bgVw+j7G+QjwKTq7DL8HLMET23X7OO4XeCKznM5r0/wRWAu87T7L3Zj3xDhArKq1YThEJENV61wG2CLgOlV9ez/PMRu4XVXPPCiDNIxDBPvWYhgd3CMi0/HcX/cfgPDcAHyRfbuzDMNwmOVjGIZhJByL+RiGYRgJx8THMAzDSDgmPoZhGEbCMfExDMMwEo6Jj2EYhpFw/j84+PeLq1D+sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram, bin_edges = np.histogram(scanner, bins=256, range=(0, 1))\n",
    "# plot histogram\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"grayscale value\")\n",
    "plt.ylabel(\"pixel count\")\n",
    "plt.xlim([0.0, 1.0])  # <- named arguments do not work here\n",
    "\n",
    "plt.plot(bin_edges[0:-1], histogram)  # <- or here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031cbe63a14e47fabd029133ed938db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=179, description='slice', max=358), IntSlider(value=5, description='i', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice=<class 'slice'>, i=5)>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c, d, e = 0, 1, 2, 2, 2\n",
    "a = 0\n",
    "b = 2\n",
    "i = 5\n",
    "def dicom_animation(slice= slice, i=i):\n",
    "    f, axarr = plt.subplots(1, 7, figsize=(15, 20))\n",
    "    axarr[0].imshow(np.swapaxes(gimages[i][slice, :, :], 1, 0), cmap=\"bone\")\n",
    "    axarr[1].imshow(np.swapaxes(scanners[i][slice, :, :], 1, 0), cmap=\"bone\")\n",
    "    axarr[2].imshow(np.swapaxes(blended_true_masks[i][:, slice, :,:], 1, 0))\n",
    "    axarr[3].imshow(np.swapaxes(blended_old_masks[i][:, slice, :,:], 1, 0))\n",
    "    axarr[4].imshow(np.swapaxes(evolutions[i][a][:, slice, :,:], 1, 0))\n",
    "    axarr[5].imshow(np.swapaxes(evolutions[i][b][:, slice, :,:], 1, 0))\n",
    "    # axarr[6].imshow(blended_evolution[c][:, slice, :,:])\n",
    "    # axarr[7].imshow(blended_evolution[d][:, slice, :,:])\n",
    "    axarr[6].imshow(np.swapaxes(blended_finals[i][:, slice, :,:], 1, 0))\n",
    "    axarr[0].set_title(\"Gaussian Gradient\")\n",
    "    axarr[1].set_title(\"Scanner\")\n",
    "    axarr[2].set_title(\"Ground Truth\")\n",
    "    axarr[3].set_title(f\"Init {dice_init[i]}\")\n",
    "    axarr[4].set_title(\"Remove small components {}\".format( dice_evolution[i][a]))\n",
    "    axarr[5].set_title(\"Active contours {}, {}\".format(b, dice_evolution[i][b]))\n",
    "    # axarr[6].set_title(\"Evolution {}, {}\".format(c, dice_scores_evol[c]))\n",
    "    # axarr[7].set_title(\"Evolution {}, {}\".format(d, dice_scores_evol[d]))\n",
    "    axarr[6].set_title(\"Expand labels {}\".format(dice_final[i]))\n",
    "    for i in range(7):\n",
    "        axarr[i].set_axis_off()\n",
    "        axarr[i].invert_xaxis()\n",
    "    # print(os.path.basename(data_dicts_test[case_number][\"image\"]))\n",
    "    # print(\"{settings}\".format(settings=settings))\n",
    "interact(dicom_animation, slice=(0,scanners[i].shape[0] - 1), i=(0, len(scanners)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_trauma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f756ff16342a8157e6f46b879d688029dcc5bc6cd621b2b84934bbdd850a743a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
