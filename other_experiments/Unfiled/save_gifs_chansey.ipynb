{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    AsChannelLastd,\n",
    "    AsChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    CropForeground,\n",
    "    SpatialCropd,\n",
    "    AsDiscreted,\n",
    "    ScaleIntensityRanged,\n",
    "    EnsureType,\n",
    "    KeepLargestConnectedComponent,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    LabelToContour,\n",
    "    FillHolesd\n",
    ")\n",
    "import glob\n",
    "from monai.transforms.transform import MapTransform\n",
    "from monai.transforms.inverse import InvertibleTransform\n",
    "from monai.data import decollate_batch\n",
    "import SimpleITK as sitk\n",
    "from monai.config import DtypeLike, KeysCollection\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "from typing import Any, Dict, Hashable, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "from monai.visualize import matshow3d, blend_images\n",
    "import torch\n",
    "from monai.metrics import DiceMetric\n",
    "import csv\n",
    "import cv2\n",
    "# import cc3d\n",
    "# import morphsnakes as ms\n",
    "import cv2\n",
    "import imageio\n",
    "from collections import Counter\n",
    "from skimage.morphology import disk, dilation, binary_dilation, ball\n",
    "\n",
    "class RefineOutput(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        old_mask_organ = np.where((d[\"label\"] != 1), 0, d[\"label\"])\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        old_mask_organ =  np.expand_dims(np.stack([cv2.dilate(old_mask_organ[0,slice,:,:],kernel,iterations = 1) for slice in range(old_mask_organ.shape[1])]),0)\n",
    "        old_mask_injury = np.where((d[\"label\"] != 2), 0, d[\"label\"]) \n",
    "        new_mask_injury = np.zeros_like(old_mask_injury)\n",
    "        new_img = d[\"image\"][:, :, :, :].copy()\n",
    "        idx_label_organ = np.where(old_mask_organ.flatten() == 1)[0] #ids of spleen\n",
    "        min_intensity = np.min(new_img[old_mask_injury!=0]) \n",
    "        idx_img = np.where((new_img.flatten() > min_intensity))[0]\n",
    "        idx_img_2 = np.where((new_img.flatten() < min_intensity +30))[0]\n",
    "        idx_img = np.intersect1d(idx_img, idx_img_2)\n",
    "        idx_to_change = np.intersect1d(idx_img, idx_label_organ)\n",
    "        np.put(new_mask_injury, idx_to_change, 1)\n",
    "        old_mask_injury += new_mask_injury\n",
    "        old_mask_injury = np.where((old_mask_injury == 3), 2, old_mask_injury) \n",
    "        old_mask_injury = np.where((old_mask_injury == 1), 2, old_mask_injury) \n",
    "\n",
    "        # closed_slices = list()\n",
    "        # for slice in range(new_mask.shape[-1]):\n",
    "        #     result = cv2.morphologyEx(\n",
    "        #         new_mask[0, :, :, slice], cv2.MORPH_CLOSE, kernel, iterations=2\n",
    "        #     )\n",
    "        #     result = cv2.medianBlur(result, 3)\n",
    "        #     closed_slices.append(result)\n",
    "\n",
    "        # new_mask = np.stack(closed_slices)\n",
    "\n",
    "        final_mask = old_mask_injury + old_mask_organ\n",
    "\n",
    "        d[\"label\"] = final_mask\n",
    "\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "class DilationLabel(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        img = d[\"label\"]\n",
    "        old_mask_injury = np.where((img != 2), 0, img)\n",
    "        if ORGAN == \"Spleen\":\n",
    "            injury_size = np.sum(old_mask_injury)/2\n",
    "            if injury_size < 4500:\n",
    "                # radius = int((injury_size/1000)*2)\n",
    "                old_mask_organ = np.where((img != 1), 0, img)\n",
    "                final_mask_injury = dilation(old_mask_injury[0,:,:,:], footprint=ball(radius=6))\n",
    "                final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "                final_mask = old_mask_organ + final_mask_injury\n",
    "                final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "                d[\"label\"] = final_mask\n",
    "            else:\n",
    "                old_mask_organ = np.where((img != 1), 0, img)\n",
    "                final_mask_injury = dilation(old_mask_injury[0,:,:,:], footprint=ball(radius=2))\n",
    "                final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "                final_mask = old_mask_organ + final_mask_injury\n",
    "                final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "                d[\"label\"] = final_mask\n",
    "        if ORGAN == \"Liver\":\n",
    "            old_mask_organ = np.where((img != 1), 0, img)\n",
    "            mask = disk(2)\n",
    "            new_mask_injury = list()\n",
    "            for slice in range(old_mask_injury.shape[1]):\n",
    "                result = dilation(old_mask_injury[0,slice,:,:], footprint=mask)\n",
    "                new_mask_injury.append(result)\n",
    "            final_mask_injury = np.stack(new_mask_injury)\n",
    "            final_mask_injury = np.expand_dims(final_mask_injury, 0).astype(np.int8)\n",
    "            final_mask = old_mask_organ + final_mask_injury\n",
    "            final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "            d[\"label\"] = final_mask\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "def fill_contours_fixed(arr):\n",
    "    slices = []\n",
    "    for _ in range(arr.shape[0]):\n",
    "        slices.append(\n",
    "        np.maximum.accumulate(arr, 1) &\\\n",
    "            np.maximum.accumulate(arr[:, :, ::-1], 1)[:, :, ::-1] &\\\n",
    "            np.maximum.accumulate(arr[:, ::-1, :], 0)[:,::-1, :] &\\\n",
    "            np.maximum.accumulate(arr[::-1, :, :], 0)[::-1, :, :] &\\\n",
    "            np.maximum.accumulate(arr, 0))\n",
    "    return np.stack(slices, 0)\n",
    "\n",
    "\n",
    "\n",
    "class ActiveContour(MapTransform):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        dtype: DtypeLike = np.float32,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(\n",
    "        self, data: Mapping[Hashable, NdarrayOrTensor]\n",
    "    ) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        label = d[\"label\"][:,:,:,:]\n",
    "        img = d[\"image\"][:,:,:,:]\n",
    "        old_mask_organ = np.where((label != 1), 0, label)\n",
    "        old_mask_injury = np.where((label != 2), 0, label)\n",
    "        # old_mask_injury = np.expand_dims(old_mask_injury,0)\n",
    "        temp_d = {\"image\": d[\"image\"], \"label\": old_mask_injury}\n",
    "        cropped_contour = CropForegroundd(keys=[\"image\", \"label\"], \n",
    "                                            source_key=\"label\",\n",
    "                                            margin=10)(temp_d)\n",
    "        cropped_img = cropped_contour[\"image\"][0,:,:,:]\n",
    "        cropped_label_injury = cropped_contour[\"label\"][0,:,:,:]\n",
    "        # gimg = ms.inverse_gaussian_gradient(cropped_img, alpha=1000, sigma=5.48)\n",
    "        # contour_injury = LabelToContour()(cropped_label_injury)\n",
    "        # label_ac = ms.morphological_geodesic_active_contour(gimg, iterations=10,\n",
    "        #                                      init_level_set=cropped_label_injury,\n",
    "        #                                      smoothing=1, threshold=0.31,\n",
    "        #                                      balloon=1)\n",
    "        label_ac = ms.morphological_chan_vese(cropped_img, 25, init_level_set=cropped_label_injury, lambda2=2)\n",
    "        label_ac = np.where((label_ac == 1), 2, label_ac)\n",
    "        cropped_contour[\"label\"] = np.expand_dims(label_ac, 0)\n",
    "        inv_cropped = CropForegroundd(keys=[\"image\", \"label\"], source_key=\"label\",\n",
    "                                            margin=30).inverse(cropped_contour)\n",
    "        label_ac = inv_cropped[\"label\"]\n",
    "        final_mask_injury = label_ac.astype(np.int8)\n",
    "        final_mask = old_mask_organ + final_mask_injury\n",
    "        final_mask = np.where((final_mask == 3), 2, final_mask)\n",
    "        d[\"label\"] = final_mask\n",
    "\n",
    "        return d\n",
    "\n",
    "def save_csv(output_path, task_name, data):\n",
    "    import csv\n",
    "\n",
    "    base_path = os.path.join(\n",
    "        HOME,\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        OUT_FOLDER,\n",
    "        GIF_FOLDER,\n",
    "        output_path)\n",
    "\n",
    "    keys = data[0].keys()\n",
    "    a_file = open(base_path, \"w+\")\n",
    "    dict_writer = csv.DictWriter(a_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(data)\n",
    "    a_file.close()\n",
    "\n",
    "\n",
    "def _save_gif(volume, filename, task_name=\"Task504_LiverTrauma\"):\n",
    "    volume = volume.astype(np.float64) / np.max(volume)  # normalize the data to 0 - 1\n",
    "    volume = volume * 255  # Now scale by 255\n",
    "    volume = volume.astype(np.uint8)\n",
    "    base_path = os.path.join(\n",
    "        HOME,\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        OUT_FOLDER,\n",
    "        GIF_FOLDER)\n",
    "    path_to_gif = os.path.join(base_path, f\"{filename}.mp4\")\n",
    "    if not os.path.exists(base_path):\n",
    "        print(\"Creating gifs directory\")\n",
    "        os.mkdir(base_path)\n",
    "    imageio.mimsave(path_to_gif, volume, fps=5)\n",
    "    return path_to_gif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"out_unet\"\n",
    "GIF_FOLDER = \"gifs\"\n",
    "ORGAN = \"Liver\"\n",
    "HOME = \"/mnt/chansey/\"\n",
    "\n",
    "task_name=\"Task510_LiverTraumaDGX\"\n",
    "    #Task511_SpleenTraumaCV Task510_LiverTraumaDGX Task512_LiverSpleenTrauma\n",
    "    \n",
    "predictions = glob.glob(\n",
    "    os.path.join(\n",
    "        HOME,\n",
    "        \"lauraalvarez\",\n",
    "        \"nnunet\",\n",
    "        \"nnUNet_raw_data\",\n",
    "        task_name,\n",
    "        OUT_FOLDER,\n",
    "        \"*.nii.gz\",\n",
    "    )\n",
    ")\n",
    "\n",
    "images = [x.replace(OUT_FOLDER,\"imagesTs\") for x in predictions]\n",
    "images = [x.replace(\".nii.gz\",\"_0000.nii.gz\") for x in images]\n",
    "true_labels = [x.replace(OUT_FOLDER,\"labelsTs\") for x in predictions]\n",
    "# true_labels = [x.replace(\"_0000.nii.gz\", \".nii.gz\") for x in true_labels]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "done = [\"TNI_000_0000\", \"TNI_002_0000\", \"TNI_004_0000\", \"TSpLi_001_0000\", \"TSpLi_003_0000\", \"TSpLi_005_0000\", \n",
    "       \"TSpLi_008_0000\", \"TSpLi_010_0000\", \"TSpLi_011_0000\", \"TSpLi_013_0000\", \"TSpLi_015_0000\"]\n",
    "\n",
    "done = [x + \".nii.gz\" for x in done]\n",
    "\n",
    "data_dicts_test = [\n",
    "    {\"image\": image_name, \"label\": label_name, \"tLabel\": true_name}\n",
    "    for image_name, label_name, true_name in zip(images, predictions, true_labels) if os.path.basename(image_name) not in done\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_002_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_002.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_002.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_000_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_000.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_000.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_006_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_006.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_006.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_004_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_004.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_004.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_008_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_008.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_008.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_005_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_005.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_005.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_003_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_003.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_003.nii.gz'},\n",
       " {'image': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_001_0000.nii.gz',\n",
       "  'label': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_001.nii.gz',\n",
       "  'tLabel': '/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_001.nii.gz'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dicts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE 006 EXCLUDED, TOO BIG FOR DIAG TO MANAGE, REDUCE SIZE TO GET SCORES EL 5 Y 9 TAMBIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\", \"tLabel\"]),\n",
    "            AddChanneld(keys=[\"label\", \"image\", \"tLabel\"]),\n",
    "            CropForegroundd(keys=[\"image\",\"tLabel\", \"label\"], source_key=\"image\"),\n",
    "            \n",
    "#             DilationLabel(keys=[\"label\"]),\n",
    "            KeepLargestConnectedComponentd(keys=[\"label\"], applied_labels=[1,2], is_onehot=False, independent=True),\n",
    "            # ActiveContour(keys=[\"label\", \"image\"]),\n",
    "            # FillHolesd(keys=[\"label\"]),\n",
    "\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-175,\n",
    "                a_max=250,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "        ]\n",
    "    )(data_dicts_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 506, 473, 1345)\n",
      "(1, 506, 473, 1345)\n",
      "(1, 506, 473, 1345)\n"
     ]
    }
   ],
   "source": [
    "print(a[\"image\"].shape)\n",
    "print(a[\"label\"].shape)\n",
    "print(a[\"tLabel\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering for \n",
      "\t image:/mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/imagesTs/TLIV_002_0000.nii.gz, \n",
      "\t label: /mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/out_unet/TLIV_002.nii.gz, \n",
      "\t true label: /mnt/chansey/lauraalvarez/nnunet/nnUNet_raw_data/Task510_LiverTraumaDGX/labelsTs/TLIV_002.nii.gz\n",
      "torch.Size([1, 3, 1569, 495, 416]) torch.Size([1, 3, 1569, 495, 416])\n",
      "{'image': 'TLIV_002_0000.nii.gz', 'dice_liver': array(0.13479035, dtype=float32), 'dice_liver_injury': array(0., dtype=float32)}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/plugins/ffmpeg.py:169\u001b[0m, in \u001b[0;36m_get_ffmpeg_api\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio_ffmpeg\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio_ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m volume \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack(\n\u001b[1;32m     66\u001b[0m     (\n\u001b[1;32m     67\u001b[0m         torch\u001b[38;5;241m.\u001b[39mfrom_numpy(inj[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m volume \u001b[38;5;241m=\u001b[39m volume\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m volume_path \u001b[38;5;241m=\u001b[39m \u001b[43m_save_gif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbasename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# _save_gif(blended_true_label.numpy().transpose(0, 1, 3, 2), f\"{basename}_True\", task_name)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# _save_gif(blended_final.numpy().transpose(0, 1, 3, 2), f\"{basename}_Pred\", task_name)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvolume_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m_save_gif\u001b[0;34m(volume, filename, task_name)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating gifs directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(base_path)\n\u001b[0;32m--> 233\u001b[0m \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmimsave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_gif\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path_to_gif\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/v2.py:331\u001b[0m, in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/core/legacy_plugin_wrapper.py:182\u001b[0m, in \u001b[0;36mLegacyPlugin.write\u001b[0;34m(self, ndimage, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, ndimage, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    Write an ndimage to the URI specified in path.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m        particular format.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mimage_mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    184\u001b[0m             writer\u001b[38;5;241m.\u001b[39mappend_data(ndimage)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/core/legacy_plugin_wrapper.py:163\u001b[0m, in \u001b[0;36mLegacyPlugin.legacy_get_writer\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Note: this will break thread-safety\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/core/format.py:234\u001b[0m, in \u001b[0;36mFormat.get_writer\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m select_mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot write in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mimage_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/core/format.py:311\u001b[0m, in \u001b[0;36mFormat._BaseReaderWriter.__init__\u001b[0;34m(self, format, request)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request \u001b[38;5;241m=\u001b[39m request\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Open the reader/writer\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/plugins/ffmpeg.py:557\u001b[0m, in \u001b[0;36mFfmpegFormat.Writer._open\u001b[0;34m(self, fps, codec, bitrate, pixelformat, ffmpeg_params, input_params, output_params, ffmpeg_log_level, quality, macro_block_size)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    546\u001b[0m     fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     macro_block_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m    556\u001b[0m ):\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ffmpeg_api \u001b[38;5;241m=\u001b[39m \u001b[43m_get_ffmpeg_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mget_local_filename()\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_trauma/lib/python3.9/site-packages/imageio/plugins/ffmpeg.py:171\u001b[0m, in \u001b[0;36m_get_ffmpeg_api\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio_ffmpeg\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use the imageio ffmpeg plugin you need to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install imageio-ffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     _ffmpeg_api \u001b[38;5;241m=\u001b[39m imageio_ffmpeg\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ffmpeg_api\n",
      "\u001b[0;31mImportError\u001b[0m: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'"
     ]
    }
   ],
   "source": [
    "\n",
    "# NOTE: POr alguna razon aqui uno de los scanneres me sale metric 0 cuando con el mismo codigo\n",
    "# en el run_metrics me sale 0.67, habra que debugear, ignorando for now.\n",
    "csv_list = []\n",
    "for data in data_dicts_test:\n",
    "    print(f\"Infering for \\n\\t image:{data['image']}, \\n\\t label: {data['label']}, \\n\\t true label: {data['tLabel']}\")\n",
    "    normal_plot = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"label\", \"tLabel\"]),\n",
    "            AsChannelFirstd(keys=[\"image\", \"label\", \"tLabel\"]),\n",
    "            AddChanneld(keys=[\"label\", \"image\", \"tLabel\"]),\n",
    "            CropForegroundd(keys=[\"image\",\"tLabel\",  \"label\"], source_key=\"image\"),\n",
    "            \n",
    "#             DilationLabel(keys=[\"label\"]),\n",
    "            KeepLargestConnectedComponentd(keys=[\"label\"], applied_labels=[1,2], is_onehot=False, independent=True),\n",
    "            # ActiveContour(keys=[\"label\", \"image\"]),\n",
    "            # FillHolesd(keys=[\"label\"]),\n",
    "\n",
    "            ScaleIntensityRanged(\n",
    "                keys=[\"image\"],\n",
    "                a_min=-175,\n",
    "                a_max=250,\n",
    "                b_min=0.0,\n",
    "                b_max=1.0,\n",
    "                clip=True,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    basename = os.path.basename(data[\"image\"])\n",
    "    injures = normal_plot(data)\n",
    "    post_pred = Compose([AsDiscrete(to_onehot=3)])\n",
    "    post_label = Compose([AsDiscrete(to_onehot=3)])\n",
    "    outputs = torch.Tensor(np.expand_dims(post_pred(torch.Tensor(injures[\"label\"])), 0))\n",
    "    labels = torch.Tensor(np.expand_dims(post_label(torch.Tensor(injures[\"tLabel\"])), 0))\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\")\n",
    "    print(outputs.shape, labels.shape)\n",
    "    dice_metric(y_pred=outputs, y=labels)\n",
    "#     dice_liver, dice_spleen, dice_liver_injury, dice_spleen_injury = dice_metric.aggregate()\n",
    "    dice_liver, dice_liver_injury = dice_metric.aggregate()\n",
    "    \n",
    "\n",
    "    dict_data = {\n",
    "        \"image\": basename,\n",
    "        \"dice_liver\": dice_liver.numpy(),\n",
    "#         \"dice_spleen\": dice_spleen.numpy(),\n",
    "        \"dice_liver_injury\": dice_liver_injury.numpy(),\n",
    "#         \"dice_spleen_injury\": dice_spleen_injury.numpy(),\n",
    "    }\n",
    "    print(dict_data)\n",
    "    csv_list.append(dict_data)\n",
    "    save_gif = True\n",
    "    if save_gif == True:\n",
    "        post_plotting = Compose([EnsureType(), AsDiscrete(argmax=False)])\n",
    "        injures[\"label\"] = post_plotting(injures[\"label\"])\n",
    "        inj = dict(injures)\n",
    "        inj = Resized(keys=[\"image\", \"label\", \"tLabel\"], spatial_size=(512, 512, 512))(\n",
    "            inj\n",
    "        )\n",
    "\n",
    "        blended_label_in = blend_images(inj[\"image\"], inj[\"label\"], 0.5)\n",
    "        blended_final = blended_label_in.permute(1, 2, 0, 3)\n",
    "\n",
    "        blended_true_label = blend_images(inj[\"image\"], inj[\"tLabel\"], 0.5)\n",
    "        blended_true_label = torch.from_numpy(blended_true_label).permute(1, 2, 0, 3)\n",
    "\n",
    "        volume = torch.hstack(\n",
    "            (\n",
    "                torch.from_numpy(inj[\"image\"]).permute(1, 2, 0, 3).repeat(1, 1, 3, 1),\n",
    "                blended_final,\n",
    "                blended_true_label,\n",
    "            )\n",
    "        )\n",
    "        volume = volume.permute(0, 1, 3, 2)\n",
    "\n",
    "        volume_path = _save_gif(volume.numpy(), f\"{basename}\", task_name)\n",
    "        # _save_gif(blended_true_label.numpy().transpose(0, 1, 3, 2), f\"{basename}_True\", task_name)\n",
    "        # _save_gif(blended_final.numpy().transpose(0, 1, 3, 2), f\"{basename}_Pred\", task_name)\n",
    "\n",
    "        print(f\"Saved {volume_path}\")\n",
    "    save_csv(\"summary.csv\", task_name, csv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/trauma/miniconda3/envs/env_trauma/lib/python3.9/site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.9 are installed in '/home/trauma/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed pip-22.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio-ffmpeg\n",
      "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
      "Successfully installed imageio-ffmpeg-0.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio-ffmpeg --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.16\n",
      "  Downloading numpy-1.16.0.zip (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py) ... \u001b[?25l/"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.16 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd953d996cbefa82e0aa9bb4569a5a9d74ea146024a460b967761e6c3fe194fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
