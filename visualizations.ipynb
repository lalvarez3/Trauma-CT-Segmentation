{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureType,\n",
    "    EnsureChannelFirstd,\n",
    "    RandFlipd,\n",
    "    RandRotated,\n",
    "    ToTensord,\n",
    "    Resized,\n",
    "    RandSpatialCropSamplesd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    "    KeepLargestConnectedComponent,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandCropByLabelClassesd\n",
    ")\n",
    "from monai.transforms.transform import MapTransform\n",
    "from monai.transforms.inverse import InvertibleTransform\n",
    "\n",
    "from monai.config import DtypeLike, KeysCollection\n",
    "from monai.config.type_definitions import NdarrayOrTensor\n",
    "from typing import Any, Dict, Hashable, List, Mapping, Optional, Sequence, Tuple, Union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveDicts(MapTransform, InvertibleTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: KeysCollection,\n",
    "        allow_missing_keys: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "    def __call__(self, data: Mapping[Hashable, NdarrayOrTensor]) -> Dict[Hashable, NdarrayOrTensor]:\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            self.push_transform(d, key)\n",
    "        # print(d[\"image_meta_dict\"][\"filename_or_obj\"])\n",
    "        a = {\"image\": d[\"image\"], \"label\": d[\"label\"], \"path\": d[\"image_meta_dict\"][\"filename_or_obj\"]}\n",
    "        # print(a[\"path\"])\n",
    "        d = a\n",
    "        return d\n",
    "\n",
    "    def inverse(self, data: Mapping[Hashable, Any]) -> Dict[Hashable, Any]:\n",
    "        d = deepcopy(dict(data))\n",
    "        for key in self.key_iterator(d):\n",
    "            d[key] = d[key]\n",
    "            # Remove the applied transform\n",
    "            self.pop_transform(d, key)\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import matshow3d, blend_images\n",
    "import imageio\n",
    "def make_gif(predictions):\n",
    "    volumes = []\n",
    "    for prediction in predictions:\n",
    "        selected = prediction\n",
    "\n",
    "        pred = torch.argmax(selected['output'], dim=1).detach().cpu().numpy()\n",
    "        true_label = torch.sum(selected['label'][:,1:,:,:,:], dim=1).detach().cpu().numpy()\n",
    "        image = selected['image'][0].cpu().numpy()\n",
    "\n",
    "        blended_true_label = blend_images(image, true_label)\n",
    "        blended_final_true_label = torch.from_numpy(blended_true_label).permute(1,2,0,3)\n",
    "\n",
    "        blended_prediction = blend_images(image, pred)\n",
    "        blended_final_prediction = torch.from_numpy(blended_prediction).permute(1,2,0,3)\n",
    "\n",
    "        volume_pred = blended_final_prediction[:,:,:,:]\n",
    "        volume_label = blended_final_true_label[:,:,:,:]\n",
    "        volume_pred = np.squeeze(volume_pred).permute(3,0,1,2)\n",
    "        volume_label = np.squeeze(volume_label).permute(3,0,1,2)\n",
    "        volume = torch.hstack((volume_pred, volume_label)).numpy()\n",
    "        volumes.append(volume)\n",
    "    volume = np.hstack((volumes))\n",
    "    data = volume.astype(np.float64) / np.max(volume) # normalize the data to 0 - 1\n",
    "    data = 255 * data # Now scale by 255\n",
    "    volume = data.astype(np.uint8)\n",
    "    path_to_gif = f'gifs\\\\prediction.gif'\n",
    "    if not os.path.exists(\"gifs\\\\\"):\n",
    "        os.mkdir(\"gifs\\\\\")\n",
    "    imageio.mimsave(path_to_gif, volume)\n",
    "    return path_to_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets.widgets import * \n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "injure_liver = os.path.join(  \"/mnt/chansey/\", \"lauraalvarez\", \"nnunet\", \"nnUNet_raw_data_base\", \"nnUNet_raw_data\", \"Task503_LiverSpleenTrauma\", \"imagesTr\", \"TRMLIV_043_0000.nii.gz\")\n",
    "injure_liver_label = os.path.join( \"/mnt/chansey/\", \"lauraalvarez\", \"nnunet\", \"nnUNet_raw_data_base\", \"nnUNet_raw_data\", \"Task503_LiverSpleenTrauma\", \"labelsTr\", \"TRMLIV_043.nii.gz\")\n",
    "\n",
    "injure_liver = '/mnt/chansey/lauraalvarez/data/liver_spleen_nnunet/train/data/L110162.mha'\n",
    "injure_liver_label = '/mnt/chansey/lauraalvarez/data/liver_spleen_nnunet/train/mask/L110162.mha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {'image': injure_liver, 'label': injure_liver_label}\n",
    "val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                # RemoveDicts(keys=[\"image\", \"label\"]),\n",
    "                # AddChanneld(keys=[\"image\", \"label\"]),\n",
    "                # Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                # Spacingd(\n",
    "                #     keys=[\"image\", \"label\"],\n",
    "                #     pixdim=(1.5, 1.5, 2.0),\n",
    "                #     mode=(\"bilinear\", \"nearest\"),\n",
    "                # ),\n",
    "                # Resized(keys=[\"image\", \"label\"], spatial_size=self.val_img_size),\n",
    "                # ScaleIntensityRanged(\n",
    "                #     keys=[\"image\"],\n",
    "                #     a_min=-175,\n",
    "                #     a_max=250,\n",
    "                #     b_min=0.0,\n",
    "                    # b_max=1.0,\n",
    "                    # clip=True,\n",
    "                # ),\n",
    "                # CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "                # RemoveDicts(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "injures = val_transforms(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([860, 1024, 184])\n",
      "torch.Size([860, 1024, 184, 6])\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(injures[\"image\"].shape)\n",
    "print(injures[\"label\"].shape)\n",
    "print(np.unique(injures[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.visualize import matshow3d, blend_images\n",
    "import torch \n",
    "\n",
    "blended_label_in = blend_images(injures[\"image\"].cpu().numpy(), injures[\"label\"].cpu().numpy())\n",
    "blended_final = torch.from_numpy(blended_label_in).permute(1,2,0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e525c21d2caa4164ab16c926441ecc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=42, description='slice', max=85), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dicom_animation(slice)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dicom_animation(slice):\n",
    "    # extent = np.min(x), np.max(x), np.min(y), np.max(y)\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.title(f\"liver no injured \")\n",
    "    plt.imshow(blended_final[:, :, :, slice], cmap=\"bone\")\n",
    "    # plt.imshow(ni_arr_label[:, :, :, slice], cmap=plt.cm.viridis, alpha=.15, interpolation=None)\n",
    "    plt.show()\n",
    "\n",
    "interact(dicom_animation, slice=(0, blended_final.shape[-1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16d90db93701a4e14595aea1a6791a3dd0d33758ed6b394279d759beaff9b73f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_trauma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
